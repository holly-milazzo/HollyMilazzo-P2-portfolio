[
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "I have journeyed the inner sanctums within the realm of Data Analytics for 8 years. In the spirit of fellowship, I have collaborated with cross-functional teams, ensuring that every stakeholder, from the boardroom to the front lines, understands the story that the data tells. Through trials and tribulations, much like the battles against Sauron’s forces, I have developed a keen eye for detecting anomalies and opportunities, ensuring the integrity and accuracy of the insights provided.\nMy hope is to glean any insights or experiences you wish to share on this quest.\nA peculiar fact about me is that I have no food allergies.\n\n\n\nClick icon to view Holly from the Shire\n\n\nMuch like the hidden gems of Middle-earth, this subreddit is filled with data visualizations guaranteed to captivate your interests: Link"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Placeholder file for the future R coding exercise."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Greetings, friend! Welcome to my little corner of the web.\n\nI am Holly Milazzo, and I’m delighted your journey has led you here.\nPlease, feel free to explore my website and data analysis portfolio.\n\nUse the Menu Bar above to look around.\nI’ve gathered many stories and wonders along my travels.\n\nMay your visit be filled with joy and discovery, and may you always find what you seek!"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "Placeholder file for the future data/results presentation exercise."
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/holly/OneDrive/Desktop/Data_Repository/Practicum II/HollyMilazzo-P2-portfolio\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          3     \n_______________________          \nColumn type frequency:           \n  factor                   1     \n  numeric                  2     \n________________________         \nGroup variables            None  \n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(dplyr) #for data processing/cleaning\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(here) #to set paths\n\nhere() starts at C:/Users/holly/OneDrive/Desktop/Data_Repository/Practicum II/HollyMilazzo-P2-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title  director cast  country date_added          release_year\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;dttm&gt;                     &lt;dbl&gt;\n1 s1      Movie   Dick … Kirsten… &lt;NA&gt;  United… 2021-09-25 00:00:00         2020\n2 s2      TV Show Blood… &lt;NA&gt;     Ama … South … 2021-09-24 00:00:00         2021\n3 s3      TV Show Gangl… Julien … Sami… &lt;NA&gt;    2021-09-24 00:00:00         2021\n4 s4      TV Show Jailb… &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;    2021-09-24 00:00:00         2021\n5 s5      TV Show Kota … &lt;NA&gt;     Mayu… India   2021-09-24 00:00:00         2021\n6 s6      TV Show Midni… Mike Fl… Kate… &lt;NA&gt;    2021-09-24 00:00:00         2021\n# ℹ 4 more variables: rating &lt;chr&gt;, duration &lt;chr&gt;, listed_in &lt;chr&gt;,\n#   description &lt;chr&gt;\n\n\n\n\nCheck data\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 8,811\nColumns: 12\n$ show_id      &lt;chr&gt; \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s1…\n$ type         &lt;chr&gt; \"Movie\", \"TV Show\", \"TV Show\", \"TV Show\", \"TV Show\", \"TV …\n$ title        &lt;chr&gt; \"Dick Johnson Is Dead\", \"Blood & Water\", \"Ganglands\", \"Ja…\n$ director     &lt;chr&gt; \"Kirsten Johnson\", NA, \"Julien Leclercq\", NA, NA, \"Mike F…\n$ cast         &lt;chr&gt; NA, \"Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Mola…\n$ country      &lt;chr&gt; \"United States\", \"South Africa\", NA, NA, \"India\", NA, NA,…\n$ date_added   &lt;dttm&gt; 2021-09-25, 2021-09-24, 2021-09-24, 2021-09-24, 2021-09-…\n$ release_year &lt;dbl&gt; 2020, 2021, 2021, 2021, 2021, 2021, 2021, 1993, 2021, 202…\n$ rating       &lt;chr&gt; \"PG-13\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"PG…\n$ duration     &lt;chr&gt; \"90 min\", \"2 Seasons\", \"1 Season\", \"1 Season\", \"2 Seasons…\n$ listed_in    &lt;chr&gt; \"Documentaries\", \"International TV Shows, TV Dramas, TV M…\n$ description  &lt;chr&gt; \"As her father nears the end of his life, filmmaker Kirst…\n\nsummary(rawdata)\n\n   show_id              type              title             director        \n Length:8811        Length:8811        Length:8811        Length:8811       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     cast             country            date_added                    \n Length:8811        Length:8811        Min.   :2008-01-01 00:00:00.00  \n Class :character   Class :character   1st Qu.:2018-04-06 00:00:00.00  \n Mode  :character   Mode  :character   Median :2019-07-02 00:00:00.00  \n                                       Mean   :2019-05-17 17:50:35.32  \n                                       3rd Qu.:2020-08-19 18:00:00.00  \n                                       Max.   :2024-04-05 00:00:00.00  \n                                       NA's   :13                      \n  release_year     rating            duration          listed_in        \n Min.   :1925   Length:8811        Length:8811        Length:8811       \n 1st Qu.:2013   Class :character   Class :character   Class :character  \n Median :2017   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2014                                                           \n 3rd Qu.:2019                                                           \n Max.   :2024                                                           \n NA's   :3                                                              \n description       \n Length:8811       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title  director cast  country date_added          release_year\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;dttm&gt;                     &lt;dbl&gt;\n1 s1      Movie   Dick … Kirsten… &lt;NA&gt;  United… 2021-09-25 00:00:00         2020\n2 s2      TV Show Blood… &lt;NA&gt;     Ama … South … 2021-09-24 00:00:00         2021\n3 s3      TV Show Gangl… Julien … Sami… &lt;NA&gt;    2021-09-24 00:00:00         2021\n4 s4      TV Show Jailb… &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;    2021-09-24 00:00:00         2021\n5 s5      TV Show Kota … &lt;NA&gt;     Mayu… India   2021-09-24 00:00:00         2021\n6 s6      TV Show Midni… Mike Fl… Kate… &lt;NA&gt;    2021-09-24 00:00:00         2021\n# ℹ 4 more variables: rating &lt;chr&gt;, duration &lt;chr&gt;, listed_in &lt;chr&gt;,\n#   description &lt;chr&gt;\n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n8811\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n1\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nshow_id\n0\n1.00\n2\n19\n0\n8811\n0\n\n\ntype\n1\n1.00\n5\n13\n0\n3\n0\n\n\ntitle\n2\n1.00\n1\n104\n0\n8806\n0\n\n\ndirector\n2636\n0.70\n2\n208\n0\n4529\n0\n\n\ncast\n826\n0.91\n3\n771\n0\n7695\n0\n\n\ncountry\n833\n0.91\n4\n123\n0\n749\n0\n\n\nrating\n6\n1.00\n1\n29\n0\n19\n0\n\n\nduration\n5\n1.00\n5\n146\n0\n221\n0\n\n\nlisted_in\n3\n1.00\n6\n79\n0\n516\n0\n\n\ndescription\n3\n1.00\n61\n248\n0\n8776\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrelease_year\n3\n1\n2014.19\n8.79\n1925\n2013\n2017\n2019\n2024\n▁▁▁▁▇\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_added\n13\n1\n2008-01-01\n2024-04-05\n2019-07-02\n1715\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\n# Handling missing values\nrawdata$director[is.na(rawdata$director)] &lt;- \"Unknown\"\n\n# Converting date formats\nrawdata$date_added &lt;- as.Date(rawdata$date_added, format = \"%m/%d/%Y\")\n\n# Standardizing categorical variables\nrawdata$type &lt;- as.factor(rawdata$type)\n\n# Convert 'type' back to factor after mutation\nrawdata$type &lt;- as.factor(rawdata$type)\n\n# Display the cleaned data\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title    director cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;fct&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt; \n1 s1      Movie   Dick Jo… Kirsten… &lt;NA&gt;  United… 2021-09-25         2020 PG-13 \n2 s2      TV Show Blood &… Unknown  Ama … South … 2021-09-24         2021 TV-MA \n3 s3      TV Show Ganglan… Julien … Sami… &lt;NA&gt;    2021-09-24         2021 TV-MA \n4 s4      TV Show Jailbir… Unknown  &lt;NA&gt;  &lt;NA&gt;    2021-09-24         2021 TV-MA \n5 s5      TV Show Kota Fa… Unknown  Mayu… India   2021-09-24         2021 TV-MA \n6 s6      TV Show Midnigh… Mike Fl… Kate… &lt;NA&gt;    2021-09-24         2021 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\n\n# Remove rows where 'type' is \"William Wyler\" or NA\ncleaned_data &lt;- rawdata %&gt;%\n  filter(type != \"William Wyler\" & type != \"Unknown\" & !is.na(type))\n\nhead(cleaned_data)\n\n# A tibble: 6 × 12\n  show_id type    title    director cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;fct&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt; \n1 s1      Movie   Dick Jo… Kirsten… &lt;NA&gt;  United… 2021-09-25         2020 PG-13 \n2 s2      TV Show Blood &… Unknown  Ama … South … 2021-09-24         2021 TV-MA \n3 s3      TV Show Ganglan… Julien … Sami… &lt;NA&gt;    2021-09-24         2021 TV-MA \n4 s4      TV Show Jailbir… Unknown  &lt;NA&gt;  &lt;NA&gt;    2021-09-24         2021 TV-MA \n5 s5      TV Show Kota Fa… Unknown  Mayu… India   2021-09-24         2021 TV-MA \n6 s6      TV Show Midnigh… Mike Fl… Kate… &lt;NA&gt;    2021-09-24         2021 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"cleaned_data.rds\")\nsaveRDS(cleaned_data, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This project uses data-set on Netflix Movies and TV shows from https://www.kaggle.com/datasets/rahulvyasm/netflix-movies-and-tv-shows.\nI first downloaded the netflix_titles.csv dataset and converted it to an xlsx format by opening a new excel file &gt; Click on Data tab &gt; click From Text/CSV &gt; Popup window will open for you to select the netflix_titles.csv file &gt; Select Import &gt; Click Load &gt; Save file\nThis dataset contains 8, 809 records and the following 12 variables:\n\nshow_id: A unique identifier for each title.\ntype: The category of the title, which is either ‘Movie’ or ‘TV Show’\ntitle: The name of the movie or TV show\ndirector: The director(s) of the movie or TV show (Contains null values for some entries, especially TV shows where this information might not be applicable)\ncast: The list of main actors/actresses in the title (Some entries might not have this information.)\ncountry: The country or countries where the movie or TV show was produced.\ndate_added: The date the title was added to Netflix.\nrelease_year: The year the movie or TV show was originally released.\nrating: The age rating of the title.\nduration: The duration of the title, in minutes for movies and seasons for TV shows\nlisted_in: The genres the title falls under.\ndescription: A brief summary of the title.\n\nYou will need to load the following packages in R: library(readxl) library(ggplot2) library(dplyr) library(tidyr) library(skimr)\nlibrary(here)\nNext, to clean the data prior to analysis you will need to…\nHandle the missing values in the ‘director’ variable: &gt;rawdata\\(director[is.na(rawdata\\)director)] &lt;- “Unknown”\nConvert the ‘date_added’ variable into an actual date format: &gt;rawdata\\(date_added &lt;- as.Date(rawdata\\)date_added, format = “%m/%d/%Y”)\nRemove rows where ‘type’ is “William Wyler” or NA and create a ‘cleaned_data’ subset: &gt;cleaned_data &lt;- rawdata %&gt;% &gt;&gt; filter(type != “William Wyler” & type != “Unknown” & !is.na(type))\nand then convert the ‘type’ variable into a factor: &gt;rawdata\\(type &lt;- as.factor(rawdata\\)type)\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  },
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch #to other formats, like html or pdf. See the Quarto documentation for other formats.*/"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "1.1 General Background Information",
    "text": "1.1 General Background Information\nThe intent of this analysis is to provide insights into how regional production practices and content types align with age rating distributions, offering valuable information for Netflix’s content acquisition and compliance strategies. This research highlights the importance of understanding content rating trends to better cater to diverse audiences and ensure appropriate content delivery."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "1.2 Description of data and data source",
    "text": "1.2 Description of data and data source\nData is on Netflix Movies and TV Shows from Kaggle.com site. The description says: “The Netflix Titles dataset is a comprehensive compilation of movies and TV shows available on Netflix, covering various aspects such as the title type, director, cast, country of production, release year, rating, duration, genres (listed in), and a brief description. This dataset is instrumental for analyzing trends in Netflix content, understanding genre popularity, and examining the distribution of content across different regions and time periods”\nThe dataset contains 8,809 observations and the following 12 variables:\n\nshow_id: A unique identifier for each title.\ntype: The category of the title, which is either ‘Movie’ or ‘TV Show’\ntitle: The name of the movie or TV show\ndirector: The director(s) of the movie or TV show (Contains null values for some entries, especially TV shows where this information might not be applicable)\ncast: The list of main actors/actresses in the title (Some entries might not have this information.)\ncountry: The country or countries where the movie or TV show was produced.\ndate_added: The date the title was added to Netflix.\nrelease_year: The year the movie or TV show was originally released.\nrating: The age rating of the title.\nduration: The duration of the title, in minutes for movies and seasons for TV shows\nlisted_in: The genres the title falls under.\ndescription: A brief summary of the title."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "1.3 Questions/Hypotheses to be addressed",
    "text": "1.3 Questions/Hypotheses to be addressed\nState the research questions you plan to answer with this analysis.\n“How do the type of content (Movie or TV Show) and the country of origin affect the distribution of age ratings on Netflix titles?”\nThis question focuses on understanding the relationship between content type, country of origin, and age ratings, which can provide valuable insights into regional production practices and content rating trends on Netflix\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the #bibtex file specified in the YAML header above (here dataanalysis_template_references.bib) and have the right bibtex key. #Then you can include like this:\nExamples of reproducible research projects can for instance be found in (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.1 Data aquisition",
    "text": "2.1 Data aquisition\nI imported the data for Netflix Movies and TV Shows which was available on Kaggle.com site. My raw data file is available through file path folders: starter-analysis-exercise &gt; data &gt; raw-data &gt; netflix_titles.xlsx"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.2 Data import and cleaning",
    "text": "2.2 Data import and cleaning\nThe file path to my code file for cleaning my dataset is: starter-analysis-exercise &gt; code &gt; processing-code &gt; processingfile\nFirst I imported the data…\n\n# Important\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\nhere are some of the initial cleaning techniques…\n\n# Handling missing values\n\nrawdata$director[is.na(rawdata$director)] &lt;- \"Unknown\"\n\n# Converting date formats\nrawdata$date_added &lt;- as.Date(rawdata$date_added, format = \"%m/%d/%Y\")\n\n# Standardizing categorical variables\n\nrawdata$type &lt;- as.factor(rawdata$type)\n\n# Display the cleaned data\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title    director cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;fct&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt; \n1 s1      Movie   Dick Jo… Kirsten… &lt;NA&gt;  United… 2021-09-25         2020 PG-13 \n2 s2      TV Show Blood &… Unknown  Ama … South … 2021-09-24         2021 TV-MA \n3 s3      TV Show Ganglan… Julien … Sami… &lt;NA&gt;    2021-09-24         2021 TV-MA \n4 s4      TV Show Jailbir… Unknown  &lt;NA&gt;  &lt;NA&gt;    2021-09-24         2021 TV-MA \n5 s5      TV Show Kota Fa… Unknown  Mayu… India   2021-09-24         2021 TV-MA \n6 s6      TV Show Midnigh… Mike Fl… Kate… &lt;NA&gt;    2021-09-24         2021 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\nI also needed to do some clean up when it came to content ‘type’ as it included unwanted values…\n\n# Remove rows where 'type' is \"William Wyler\" or NA\ncleaned_data &lt;- rawdata[rawdata$type != \"William Wyler\" & rawdata$type != \"Unknown\" & !is.na(rawdata$type), ]\n\nWrite code that reads in the file and cleans it so it’s ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.3 Statistical analysis",
    "text": "2.3 Statistical analysis\nExplain anything related to your statistical analyses.\nThe relevant variables I’ll be using during my statistical analysis to determine how regional production practices and content types align with age rating distributions will be: Country, Type, and Rating.\n\nsummary(cleaned_data)\n\n   show_id                     type         title             director        \n Length:8809        Movie        :6132   Length:8809        Length:8809       \n Class :character   TV Show      :2677   Class :character   Class :character  \n Mode  :character   William Wyler:   0   Mode  :character   Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n     cast             country            date_added          release_year \n Length:8809        Length:8809        Min.   :2008-01-01   Min.   :1925  \n Class :character   Class :character   1st Qu.:2018-04-06   1st Qu.:2013  \n Mode  :character   Mode  :character   Median :2019-07-02   Median :2017  \n                                       Mean   :2019-05-17   Mean   :2014  \n                                       3rd Qu.:2020-08-19   3rd Qu.:2019  \n                                       Max.   :2024-04-05   Max.   :2024  \n                                       NA's   :11           NA's   :1     \n    rating            duration          listed_in         description       \n Length:8809        Length:8809        Length:8809        Length:8809       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Exploratory/Descriptive analysis",
    "text": "3.1 Exploratory/Descriptive analysis\n\n# Perform the group_by and summarise operations\ntype_distribution &lt;- aggregate(. ~ type, data = cleaned_data, FUN = length)\nnames(type_distribution)[2] &lt;- \"count\"\n\n# Plot the distribution of content types\nbarplot(height = type_distribution$count,\n        names.arg = type_distribution$type,\n        col = c(\"purple\", \"orange\"),\n        main = \"Distribution of Content Types - Movies v TV Shows\",\n        xlab = \"Type\",\n        ylab = \"Count\",\n        las = 1) # las = 1 makes axis labels horizontal\n\n\n\n\nWe see from the distribution that it appears movies are being streamed substantially more than TV shows, but to get a better sense of this let’s represent it as a percentage instead\n\ntype_distribution &lt;- aggregate(. ~ type, data = cleaned_data, FUN = length)\nnames(type_distribution)[2] &lt;- \"count\"\n\ntype_distribution$percentage &lt;- round((type_distribution$count / sum(type_distribution$count)) * 100, 1)\n\nlabels &lt;- paste(type_distribution$type, type_distribution$percentage, \"%\")\n\npie(type_distribution$count,\n    labels = labels,\n    col = c(\"purple\", \"orange\"),\n    main = \"Percentage of Movies vs TV Shows\")\n\n\n\n\nNow I’d like to see which countries the Movie/TV show content originate from\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\ncountry_counts &lt;- head(sort(table(cleaned_data$country), decreasing = TRUE), 10)\n\n# Convert to data frame for ggplot\ncountry_df &lt;- data.frame(\n  country = names(country_counts),\n  count = as.numeric(country_counts)\n)\n\n# Create the bar chart\np &lt;- ggplot(country_df, aes(x = reorder(country, -count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"purple\") +\n  geom_text(aes(label = count), vjust = -0.3) +\n  labs(x = \"Country\", y = \"Count\", title = \"Top 10 Countries (Top 3 Highlighted)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_bar(data = country_df[1:3, ], aes(x = country, y = count), stat = \"identity\", fill = \"orange\")\n\nprint(p)\n\n\n\n\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\nTable 1 shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I recommend the here package, but I’m showing the other approach here just in case you encounter it.\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nfactor.ordered\nfactor.n_unique\nfactor.top_counts\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\nfactor\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nHeight\n0\n1\nNA\nNA\nNA\n165.66667\n15.97655\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nnumeric\nWeight\n0\n1\nNA\nNA\nNA\n70.11111\n21.24526\n45\n55\n70\n80\n110\n▇▂▃▂▂"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Basic statistical analysis",
    "text": "3.2 Basic statistical analysis\nTo get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any “p&lt;0.05 means statistical significance” interpretation is not valid.\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\nFigure 1: Height and weight stratified by gender."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Full analysis",
    "text": "3.3 Full analysis\nUse one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n149.2726967\n23.3823360\n6.3839942\n0.0013962\n\n\nWeight\n0.2623972\n0.3512436\n0.7470519\n0.4886517\n\n\nGenderM\n-2.1244913\n15.5488953\n-0.1366329\n0.8966520\n\n\nGenderO\n-4.7644739\n19.0114155\n-0.2506112\n0.8120871"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Summary and Interpretation",
    "text": "4.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Strengths and Limitations",
    "text": "4.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Conclusions",
    "text": "4.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, et al., 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word references.bib but giving it a more descriptive name is probably better."
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise - Assignment #4",
    "section": "",
    "text": "For this assigment, I am choosing Option 1: Using a complex data (in this case a Text dataset)\nFirst, I need to install the tidytext package and in this case I’ll be using a text dataset from the janeaustenr package available in R that contains the 6 different novels written by Jane Austen. I’m using the example available in the Complex Data Types unit.\n\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.3.3\n\nlibrary(janeaustenr)\n\nWarning: package 'janeaustenr' was built under R version 4.3.3\n\n\nI will also need the dplyr package for some of the functions it offers (such as pipes) in making data manipulation easier\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nhead(austen_books)\n\n                                                                                                            \n1 function ()                                                                                               \n2 {                                                                                                         \n3     books &lt;- list(`Sense & Sensibility` = janeaustenr::sensesensibility,                                  \n4         `Pride & Prejudice` = janeaustenr::prideprejudice, `Mansfield Park` = janeaustenr::mansfieldpark, \n5         Emma = janeaustenr::emma, `Northanger Abbey` = janeaustenr::northangerabbey,                      \n6         Persuasion = janeaustenr::persuasion)                                                             \n\n\nI’m going to create two new columns for ‘book’ and ‘line’ from the dataset by first grouping the data by book,and using ‘mutate’ to transform the grouped books into a line number within each book. Basically numbering the lines within the books. We can then ungroup the dataset as we have our lines:\n\noriginal_books &lt;- austen_books() %&gt;%\n  group_by(book) %&gt;%\n  mutate(line = row_number()) %&gt;%\n  ungroup()\n\noriginal_books\n\n# A tibble: 73,422 × 3\n   text                    book                 line\n   &lt;chr&gt;                   &lt;fct&gt;               &lt;int&gt;\n 1 \"SENSE AND SENSIBILITY\" Sense & Sensibility     1\n 2 \"\"                      Sense & Sensibility     2\n 3 \"by Jane Austen\"        Sense & Sensibility     3\n 4 \"\"                      Sense & Sensibility     4\n 5 \"(1811)\"                Sense & Sensibility     5\n 6 \"\"                      Sense & Sensibility     6\n 7 \"\"                      Sense & Sensibility     7\n 8 \"\"                      Sense & Sensibility     8\n 9 \"\"                      Sense & Sensibility     9\n10 \"CHAPTER 1\"             Sense & Sensibility    10\n# ℹ 73,412 more rows\n\n\nUsing the ‘unnest_tokens’ function from tidytext we can convert the text into “tokens” or individual words:\n\ntidy_books &lt;- original_books %&gt;%\n  unnest_tokens(word, text)\n\ntidy_books\n\n# A tibble: 725,055 × 3\n   book                 line word       \n   &lt;fct&gt;               &lt;int&gt; &lt;chr&gt;      \n 1 Sense & Sensibility     1 sense      \n 2 Sense & Sensibility     1 and        \n 3 Sense & Sensibility     1 sensibility\n 4 Sense & Sensibility     3 by         \n 5 Sense & Sensibility     3 jane       \n 6 Sense & Sensibility     3 austen     \n 7 Sense & Sensibility     5 1811       \n 8 Sense & Sensibility    10 chapter    \n 9 Sense & Sensibility    10 1          \n10 Sense & Sensibility    13 the        \n# ℹ 725,045 more rows\n\n\nI use the ‘anti_join(get_stopwords())’ functions together next to remove “stop words” from the dataset such as “the”, “in”, and “is”. For this you will have to use the “stopwords” package to identify those words.\n\nlibrary(stopwords)\n\nWarning: package 'stopwords' was built under R version 4.3.3\n\n\n\ntidy_books &lt;- tidy_books %&gt;%\n  anti_join(get_stopwords(), by = \"word\")\n\nNow to perform some exploratory analysis with the data set.\nlet’s install ‘ggplot2’ for our visualizations\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nIn this resource example, we can assign sentiment (positive, negative, and neutral) to the words used within the novels to perhaps get an overall idea of the emotion/feelings/theme within the novels - for this we need the ‘bing’ package for lexicon/sentiment:\n\nlibrary(tidyr)\nget_sentiments(\"bing\")\n\n# A tibble: 6,786 × 2\n   word        sentiment\n   &lt;chr&gt;       &lt;chr&gt;    \n 1 2-faces     negative \n 2 abnormal    negative \n 3 abolish     negative \n 4 abominable  negative \n 5 abominably  negative \n 6 abominate   negative \n 7 abomination negative \n 8 abort       negative \n 9 aborted     negative \n10 aborts      negative \n# ℹ 6,776 more rows\n\n\nApplying the lexicon/sentiment dataset to the text dataset using an inner join and creating new columns to represent the count of negative/positive and sentiment.\n\njaneaustensentiment &lt;- tidy_books %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = \"word\", relationship = \"many-to-many\") %&gt;% \n  count(book, index = line %/% 80, sentiment) %&gt;% \n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% \n  mutate(sentiment = positive - negative)\n\njaneaustensentiment\n\n# A tibble: 920 × 5\n   book                index negative positive sentiment\n   &lt;fct&gt;               &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;     &lt;int&gt;\n 1 Sense & Sensibility     0       16       32        16\n 2 Sense & Sensibility     1       19       53        34\n 3 Sense & Sensibility     2       12       31        19\n 4 Sense & Sensibility     3       15       31        16\n 5 Sense & Sensibility     4       16       34        18\n 6 Sense & Sensibility     5       16       51        35\n 7 Sense & Sensibility     6       24       40        16\n 8 Sense & Sensibility     7       23       51        28\n 9 Sense & Sensibility     8       30       40        10\n10 Sense & Sensibility     9       15       19         4\n# ℹ 910 more rows\n\n\nWe can now graph our sentiment count results using ggplot:\n\nggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(vars(book), ncol = 2, scales = \"free_x\")"
  }
]