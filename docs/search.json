[
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "I have journeyed the inner sanctums within the realm of Data Analytics for 8 years. In the spirit of fellowship, I have collaborated with cross-functional teams, ensuring that every stakeholder, from the boardroom to the front lines, understands the story that the data tells. Through trials and tribulations, much like the battles against Sauron’s forces, I have developed a keen eye for detecting anomalies and opportunities, ensuring the integrity and accuracy of the insights provided.\nMy hope is to glean any insights or experiences you wish to share on this quest.\nA peculiar fact about me is that I have no food allergies.\n\n\n\nClick icon to view Holly from the Shire\n\n\nMuch like the hidden gems of Middle-earth, this subreddit is filled with data visualizations guaranteed to captivate your interests: Link"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Placeholder file for the future R coding exercise."
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise - Assignment #4",
    "section": "",
    "text": "For this assigment, I am choosing Option 1: Using a complex data (in this case a Text dataset)\nFirst, I need to install the tidytext package and in this case I’ll be using a text dataset from the janeaustenr package available in R that contains the 6 different novels written by Jane Austen. I’m using the example available in the Complex Data Types unit.\n\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.3.3\n\nlibrary(janeaustenr)\n\nWarning: package 'janeaustenr' was built under R version 4.3.3\n\n\nI will also need the dplyr package for some of the functions it offers (such as pipes) in making data manipulation easier\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nhead(austen_books)\n\n                                                                                                            \n1 function ()                                                                                               \n2 {                                                                                                         \n3     books &lt;- list(`Sense & Sensibility` = janeaustenr::sensesensibility,                                  \n4         `Pride & Prejudice` = janeaustenr::prideprejudice, `Mansfield Park` = janeaustenr::mansfieldpark, \n5         Emma = janeaustenr::emma, `Northanger Abbey` = janeaustenr::northangerabbey,                      \n6         Persuasion = janeaustenr::persuasion)                                                             \n\n\nI’m going to create two new columns for ‘book’ and ‘line’ from the dataset by first grouping the data by book,and using ‘mutate’ to transform the grouped books into a line number within each book. Basically numbering the lines within the books. We can then ungroup the dataset as we have our lines:\n\noriginal_books &lt;- austen_books() %&gt;%\n  group_by(book) %&gt;%\n  mutate(line = row_number()) %&gt;%\n  ungroup()\n\noriginal_books\n\n# A tibble: 73,422 × 3\n   text                    book                 line\n   &lt;chr&gt;                   &lt;fct&gt;               &lt;int&gt;\n 1 \"SENSE AND SENSIBILITY\" Sense & Sensibility     1\n 2 \"\"                      Sense & Sensibility     2\n 3 \"by Jane Austen\"        Sense & Sensibility     3\n 4 \"\"                      Sense & Sensibility     4\n 5 \"(1811)\"                Sense & Sensibility     5\n 6 \"\"                      Sense & Sensibility     6\n 7 \"\"                      Sense & Sensibility     7\n 8 \"\"                      Sense & Sensibility     8\n 9 \"\"                      Sense & Sensibility     9\n10 \"CHAPTER 1\"             Sense & Sensibility    10\n# ℹ 73,412 more rows\n\n\nUsing the ‘unnest_tokens’ function from tidytext we can convert the text into “tokens” or individual words:\n\ntidy_books &lt;- original_books %&gt;%\n  unnest_tokens(word, text)\n\ntidy_books\n\n# A tibble: 725,055 × 3\n   book                 line word       \n   &lt;fct&gt;               &lt;int&gt; &lt;chr&gt;      \n 1 Sense & Sensibility     1 sense      \n 2 Sense & Sensibility     1 and        \n 3 Sense & Sensibility     1 sensibility\n 4 Sense & Sensibility     3 by         \n 5 Sense & Sensibility     3 jane       \n 6 Sense & Sensibility     3 austen     \n 7 Sense & Sensibility     5 1811       \n 8 Sense & Sensibility    10 chapter    \n 9 Sense & Sensibility    10 1          \n10 Sense & Sensibility    13 the        \n# ℹ 725,045 more rows\n\n\nI use the ‘anti_join(get_stopwords())’ functions together next to remove “stop words” from the dataset such as “the”, “in”, and “is”. For this you will have to use the “stopwords” package to identify those words.\n\nlibrary(stopwords)\n\nWarning: package 'stopwords' was built under R version 4.3.3\n\n\n\ntidy_books &lt;- tidy_books %&gt;%\n  anti_join(get_stopwords(), by = \"word\")\n\nNow to perform some exploratory analysis with the data set.\nlet’s install ‘ggplot2’ for our visualizations\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nIn this resource example, we can assign sentiment (positive, negative, and neutral) to the words used within the novels to perhaps get an overall idea of the emotion/feelings/theme within the novels - for this we need the ‘bing’ package for lexicon/sentiment:\n\nlibrary(tidyr)\nget_sentiments(\"bing\")\n\n# A tibble: 6,786 × 2\n   word        sentiment\n   &lt;chr&gt;       &lt;chr&gt;    \n 1 2-faces     negative \n 2 abnormal    negative \n 3 abolish     negative \n 4 abominable  negative \n 5 abominably  negative \n 6 abominate   negative \n 7 abomination negative \n 8 abort       negative \n 9 aborted     negative \n10 aborts      negative \n# ℹ 6,776 more rows\n\n\nApplying the lexicon/sentiment dataset to the text dataset using an inner join and creating new columns to represent the count of negative/positive and sentiment.\n\njaneaustensentiment &lt;- tidy_books %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = \"word\", relationship = \"many-to-many\") %&gt;% \n  count(book, index = line %/% 80, sentiment) %&gt;% \n  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% \n  mutate(sentiment = positive - negative)\n\njaneaustensentiment\n\n# A tibble: 920 × 5\n   book                index negative positive sentiment\n   &lt;fct&gt;               &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;     &lt;int&gt;\n 1 Sense & Sensibility     0       16       32        16\n 2 Sense & Sensibility     1       19       53        34\n 3 Sense & Sensibility     2       12       31        19\n 4 Sense & Sensibility     3       15       31        16\n 5 Sense & Sensibility     4       16       34        18\n 6 Sense & Sensibility     5       16       51        35\n 7 Sense & Sensibility     6       24       40        16\n 8 Sense & Sensibility     7       23       51        28\n 9 Sense & Sensibility     8       30       40        10\n10 Sense & Sensibility     9       15       19         4\n# ℹ 910 more rows\n\n\nWe can now graph our sentiment count results using ggplot:\n\nggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(vars(book), ncol = 2, scales = \"free_x\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Greetings, friend! Welcome to my little corner of the web.\n\nI am Holly Milazzo, and I’m delighted your journey has led you here.\nPlease, feel free to explore my website and data analysis portfolio.\n\nUse the Menu Bar above to look around.\nI’ve gathered many stories and wonders along my travels.\n\nMay your visit be filled with joy and discovery, and may you always find what you seek!"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "In this exercise, I recreated the bar graph that illustrates the share of political donations from team owners in six major sports leagues (NFL, NBA, WNBA, NHL, MLB, and NASCAR) to the Republican and Democratic parties over three election years: 2016, 2018, and 2020 from the FiveThirtyEight page here Link. The graph shows a significant majority of donations going to the Republican party in all three years. The annotation highlights that Giants owner Charles Johnson’s contributions constitute a substantial portion of the total Republican donations, underscoring the influence of individual donors in political contributions.\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\n\n# Important\n# Define the data location\ndata_location_sports &lt;- here::here(\"presentation-exercise\", \"sports-political-donations.csv\")\n\n# Read the CSV data\nrawdata_sports &lt;- read_csv(data_location_sports, col_names = FALSE)\n\nRows: 2799 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): X1, X2, X3, X4, X5, X6, X7\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Preview the data\nhead(rawdata_sports)\n\n# A tibble: 6 × 7\n  X1          X2           X3     X4                           X5    X6    X7   \n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Owner       Team         League Recipient                    Amou… Elec… Party\n2 Adam Silver Commissioner NBA    WRIGHT 2016                  $4,0… 2016  Demo…\n3 Adam Silver Commissioner NBA    BIDEN FOR PRESIDENT          $2,8… 2020  Demo…\n4 Adam Silver Commissioner NBA    CORY 2020                    $2,7… 2020  Demo…\n5 Adam Silver Commissioner NBA    Kamala Harris for the People $2,7… 2020  Demo…\n6 Adam Silver Commissioner NBA    Win The Era PAC              $2,7… 2020  Demo…\n\n\n\n# Assign proper column names\ncolnames(rawdata_sports) &lt;- c(\"Owner\", \"Team\", \"League\", \"Recipient\", \"Amount\", \"Election_Year\", \"Party\")\n\n# Clean up the Amount column (remove '$' and convert to numeric)\nrawdata_sports$Amount &lt;- as.numeric(gsub(\"[\\\\$,]\", \"\", rawdata_sports$Amount))\n\nWarning: NAs introduced by coercion\n\n# Filter out rows where Party is not 'Democrat' or 'Republican'\nrawdata_sports &lt;- rawdata_sports[rawdata_sports$Party %in% c(\"Democrat\", \"Republican\"), ]\n\n# Summarize data to calculate total donations by Party and Year\ndonations_summary &lt;- aggregate(rawdata_sports$Amount, \n                               by = list(Election_Year = rawdata_sports$Election_Year, Party = rawdata_sports$Party), \n                               FUN = sum)\ncolnames(donations_summary)[3] &lt;- \"Total_Amount\"\n\n# Convert Party to factor and specify order (Democrat first for better visualization)\ndonations_summary$Party &lt;- factor(donations_summary$Party, levels = c(\"Democrat\", \"Republican\"))\n\n# Calculate the proportion of total donations by year\ntotal_by_year &lt;- aggregate(donations_summary$Total_Amount, \n                           by = list(Election_Year = donations_summary$Election_Year), \n                           FUN = sum)\ncolnames(total_by_year)[2] &lt;- \"Yearly_Total\"\n\ndonations_summary &lt;- merge(donations_summary, total_by_year, by = \"Election_Year\")\ndonations_summary$Prop_Amount &lt;- donations_summary$Total_Amount / donations_summary$Yearly_Total\n\n# Plot the data\nggplot(donations_summary, aes(x = as.factor(Election_Year), y = Prop_Amount, fill = Party)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_manual(values = c(\"Democrat\" = \"blue\", \"Republican\" = \"red\")) +\n  labs(\n    title = \"Team owners give largely to the GOP\",\n    subtitle = \"Share of donations from team owners in six leagues, per year and party\",\n    x = \"\",\n    y = \"Share of Donations\",\n    fill = \"Donations to\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.background = element_rect(fill = \"gray90\"),\n    plot.background = element_rect(fill = \"gray90\"),\n    axis.text.x = element_text(angle = 0, hjust = 0.5),\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  annotate(\"text\", x = 1.5, y = 1.05, label = \"Giants owner Charles Johnson’s total contributions make up 32.1% of all Republican contributions.\", size = 3, hjust = 0.3, vjust = 0)\n\n\n\n\nTable: Partisan Contributions by League\nThe table breaks down the total political contributions from owners and commissioners in six sports leagues (MLB, NBA, NHL, NFL, WNBA, and NASCAR) to the Republican and Democratic parties from 2016 to 2020. It reveals that MLB owners have donated the most overall, with significant amounts going to both parties, but predominantly to Republicans. The table provides a clear comparison of partisan contributions across different leagues, highlighting the disparity in political support within the sports industry.\nBoth visuals emphasize the substantial financial support sports team owners provide to political parties, predominantly favoring the Republican party, and the considerable influence of a few key donors.\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(ggtext)\n\n# Define the data for the table\ndata_table &lt;- data.frame(\n  League = c(\"MLB\", \"NBA\", \"NHL\", \"NFL\", \"WNBA\", \"NASCAR\"),\n  To_Republicans = c(\"$15,181,761\", \"$8,372,300\", \"$7,087,116\", \"$5,032,470\", \"$1,338,459\", \"$576,110\"),\n  To_Democrats = c(\"$5,184,604\", \"$2,641,487\", \"$1,726,733\", \"$873,500\", \"$1,634,153\", \"$93,983\"),\n  Total = c(\"$20,366,365\", \"$11,013,787\", \"$8,813,849\", \"$5,905,970\", \"$2,972,612\", \"$670,093\")\n)\n\n# Create a base plot\np &lt;- ggplot(data_table, aes(x = 1, y = League)) +\n  geom_text(aes(label = To_Republicans, x = 2), hjust = 0, color = \"red\") +\n  geom_text(aes(label = To_Democrats, x = 3), hjust = 0, color = \"blue\") +\n  geom_text(aes(label = Total, x = 4), hjust = 0) +\n  geom_text(aes(label = League, x = 0), hjust = 0, fontface = \"bold\") +\n  scale_x_continuous(limits = c(-0.5, 4.5), breaks = 0:4, labels = c(\"LEAGUE\", \"TO REPUBLICANS\", \"TO DEMOCRATS\", \"TOTAL\", \"\")) +\n  theme_void() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 10, hjust = 0.5),\n    plot.caption = element_text(size = 8, hjust = 0.5),\n    axis.text.x = element_text(size = 10, face = \"bold\"),\n    plot.background = element_rect(fill = \"white\", color = \"white\"),\n    panel.background = element_rect(fill = \"white\", color = \"white\")\n  ) +\n  labs(\n    title = \"MLB owners have donated the most\",\n    subtitle = \"Specifically partisan contributions from owners and commissioners in the NFL, NBA, WNBA, NHL, MLB and NASCAR, by party, 2016-20\",\n    caption = \"SOURCE: FEDERAL ELECTION COMMISSION, OPENSECRETS\"\n  )\n\n# Print the plot\nprint(p)"
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/holly/OneDrive/Desktop/Data_Repository/Practicum II/HollyMilazzo-P2-portfolio\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          3     \n_______________________          \nColumn type frequency:           \n  factor                   1     \n  numeric                  2     \n________________________         \nGroup variables            None  \n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(dplyr) #for data processing/cleaning\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(here) #to set paths\n\nhere() starts at C:/Users/holly/OneDrive/Desktop/Data_Repository/Practicum II/HollyMilazzo-P2-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title  director cast  country date_added          release_year\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;dttm&gt;                     &lt;dbl&gt;\n1 s1      Movie   Dick … Kirsten… &lt;NA&gt;  United… 2021-09-25 00:00:00         2020\n2 s2      TV Show Blood… &lt;NA&gt;     Ama … South … 2021-09-24 00:00:00         2021\n3 s3      TV Show Gangl… Julien … Sami… &lt;NA&gt;    2021-09-24 00:00:00         2021\n4 s4      TV Show Jailb… &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;    2021-09-24 00:00:00         2021\n5 s5      TV Show Kota … &lt;NA&gt;     Mayu… India   2021-09-24 00:00:00         2021\n6 s6      TV Show Midni… Mike Fl… Kate… &lt;NA&gt;    2021-09-24 00:00:00         2021\n# ℹ 4 more variables: rating &lt;chr&gt;, duration &lt;chr&gt;, listed_in &lt;chr&gt;,\n#   description &lt;chr&gt;\n\n\n\n\nCheck data\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 8,811\nColumns: 12\n$ show_id      &lt;chr&gt; \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s1…\n$ type         &lt;chr&gt; \"Movie\", \"TV Show\", \"TV Show\", \"TV Show\", \"TV Show\", \"TV …\n$ title        &lt;chr&gt; \"Dick Johnson Is Dead\", \"Blood & Water\", \"Ganglands\", \"Ja…\n$ director     &lt;chr&gt; \"Kirsten Johnson\", NA, \"Julien Leclercq\", NA, NA, \"Mike F…\n$ cast         &lt;chr&gt; NA, \"Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Mola…\n$ country      &lt;chr&gt; \"United States\", \"South Africa\", NA, NA, \"India\", NA, NA,…\n$ date_added   &lt;dttm&gt; 2021-09-25, 2021-09-24, 2021-09-24, 2021-09-24, 2021-09-…\n$ release_year &lt;dbl&gt; 2020, 2021, 2021, 2021, 2021, 2021, 2021, 1993, 2021, 202…\n$ rating       &lt;chr&gt; \"PG-13\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"TV-MA\", \"PG…\n$ duration     &lt;chr&gt; \"90 min\", \"2 Seasons\", \"1 Season\", \"1 Season\", \"2 Seasons…\n$ listed_in    &lt;chr&gt; \"Documentaries\", \"International TV Shows, TV Dramas, TV M…\n$ description  &lt;chr&gt; \"As her father nears the end of his life, filmmaker Kirst…\n\nsummary(rawdata)\n\n   show_id              type              title             director        \n Length:8811        Length:8811        Length:8811        Length:8811       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     cast             country            date_added                    \n Length:8811        Length:8811        Min.   :2008-01-01 00:00:00.00  \n Class :character   Class :character   1st Qu.:2018-04-06 00:00:00.00  \n Mode  :character   Mode  :character   Median :2019-07-02 00:00:00.00  \n                                       Mean   :2019-05-17 17:50:35.32  \n                                       3rd Qu.:2020-08-19 18:00:00.00  \n                                       Max.   :2024-04-05 00:00:00.00  \n                                       NA's   :13                      \n  release_year     rating            duration          listed_in        \n Min.   :1925   Length:8811        Length:8811        Length:8811       \n 1st Qu.:2013   Class :character   Class :character   Class :character  \n Median :2017   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2014                                                           \n 3rd Qu.:2019                                                           \n Max.   :2024                                                           \n NA's   :3                                                              \n description       \n Length:8811       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title  director cast  country date_added          release_year\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;dttm&gt;                     &lt;dbl&gt;\n1 s1      Movie   Dick … Kirsten… &lt;NA&gt;  United… 2021-09-25 00:00:00         2020\n2 s2      TV Show Blood… &lt;NA&gt;     Ama … South … 2021-09-24 00:00:00         2021\n3 s3      TV Show Gangl… Julien … Sami… &lt;NA&gt;    2021-09-24 00:00:00         2021\n4 s4      TV Show Jailb… &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;    2021-09-24 00:00:00         2021\n5 s5      TV Show Kota … &lt;NA&gt;     Mayu… India   2021-09-24 00:00:00         2021\n6 s6      TV Show Midni… Mike Fl… Kate… &lt;NA&gt;    2021-09-24 00:00:00         2021\n# ℹ 4 more variables: rating &lt;chr&gt;, duration &lt;chr&gt;, listed_in &lt;chr&gt;,\n#   description &lt;chr&gt;\n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n8811\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n1\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nshow_id\n0\n1.00\n2\n19\n0\n8811\n0\n\n\ntype\n1\n1.00\n5\n13\n0\n3\n0\n\n\ntitle\n2\n1.00\n1\n104\n0\n8806\n0\n\n\ndirector\n2636\n0.70\n2\n208\n0\n4529\n0\n\n\ncast\n826\n0.91\n3\n771\n0\n7695\n0\n\n\ncountry\n833\n0.91\n4\n123\n0\n749\n0\n\n\nrating\n6\n1.00\n1\n29\n0\n19\n0\n\n\nduration\n5\n1.00\n5\n146\n0\n221\n0\n\n\nlisted_in\n3\n1.00\n6\n79\n0\n516\n0\n\n\ndescription\n3\n1.00\n61\n248\n0\n8776\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrelease_year\n3\n1\n2014.19\n8.79\n1925\n2013\n2017\n2019\n2024\n▁▁▁▁▇\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate_added\n13\n1\n2008-01-01\n2024-04-05\n2019-07-02\n1715\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\n# Handling missing values\nrawdata$director[is.na(rawdata$director)] &lt;- \"Unknown\"\n\n# Converting date formats\nrawdata$date_added &lt;- as.Date(rawdata$date_added, format = \"%m/%d/%Y\")\n\n# Standardizing categorical variables\nrawdata$type &lt;- as.factor(rawdata$type)\n\n# Convert 'type' back to factor after mutation\nrawdata$type &lt;- as.factor(rawdata$type)\n\n# Display the cleaned data\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title    director cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;fct&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt; \n1 s1      Movie   Dick Jo… Kirsten… &lt;NA&gt;  United… 2021-09-25         2020 PG-13 \n2 s2      TV Show Blood &… Unknown  Ama … South … 2021-09-24         2021 TV-MA \n3 s3      TV Show Ganglan… Julien … Sami… &lt;NA&gt;    2021-09-24         2021 TV-MA \n4 s4      TV Show Jailbir… Unknown  &lt;NA&gt;  &lt;NA&gt;    2021-09-24         2021 TV-MA \n5 s5      TV Show Kota Fa… Unknown  Mayu… India   2021-09-24         2021 TV-MA \n6 s6      TV Show Midnigh… Mike Fl… Kate… &lt;NA&gt;    2021-09-24         2021 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\n\n# Remove rows where 'type' is \"William Wyler\" or NA\ncleaned_data &lt;- rawdata %&gt;%\n  filter(type != \"William Wyler\" & type != \"Unknown\" & !is.na(type))\n\nhead(cleaned_data)\n\n# A tibble: 6 × 12\n  show_id type    title    director cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;fct&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt; \n1 s1      Movie   Dick Jo… Kirsten… &lt;NA&gt;  United… 2021-09-25         2020 PG-13 \n2 s2      TV Show Blood &… Unknown  Ama … South … 2021-09-24         2021 TV-MA \n3 s3      TV Show Ganglan… Julien … Sami… &lt;NA&gt;    2021-09-24         2021 TV-MA \n4 s4      TV Show Jailbir… Unknown  &lt;NA&gt;  &lt;NA&gt;    2021-09-24         2021 TV-MA \n5 s5      TV Show Kota Fa… Unknown  Mayu… India   2021-09-24         2021 TV-MA \n6 s6      TV Show Midnigh… Mike Fl… Kate… &lt;NA&gt;    2021-09-24         2021 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"cleaned_data.rds\")\nsaveRDS(cleaned_data, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This project uses data-set on Netflix Movies and TV shows from https://www.kaggle.com/datasets/rahulvyasm/netflix-movies-and-tv-shows.\nI first downloaded the netflix_titles.csv dataset and converted it to an xlsx format by opening a new excel file &gt; Click on Data tab &gt; click From Text/CSV &gt; Popup window will open for you to select the netflix_titles.csv file &gt; Select Import &gt; Click Load &gt; Save file\nThis dataset contains 8, 809 records and the following 12 variables:\n\nshow_id: A unique identifier for each title.\ntype: The category of the title, which is either ‘Movie’ or ‘TV Show’\ntitle: The name of the movie or TV show\ndirector: The director(s) of the movie or TV show (Contains null values for some entries, especially TV shows where this information might not be applicable)\ncast: The list of main actors/actresses in the title (Some entries might not have this information.)\ncountry: The country or countries where the movie or TV show was produced.\ndate_added: The date the title was added to Netflix.\nrelease_year: The year the movie or TV show was originally released.\nrating: The age rating of the title.\nduration: The duration of the title, in minutes for movies and seasons for TV shows\nlisted_in: The genres the title falls under.\ndescription: A brief summary of the title.\n\nYou will need to load the following packages in R: library(readxl) library(ggplot2) library(dplyr) library(tidyr) library(skimr)\nlibrary(here)\nNext, to clean the data prior to analysis you will need to…\nHandle the missing values in the ‘director’ variable: &gt;rawdata\\(director[is.na(rawdata\\)director)] &lt;- “Unknown”\nConvert the ‘date_added’ variable into an actual date format: &gt;rawdata\\(date_added &lt;- as.Date(rawdata\\)date_added, format = “%m/%d/%Y”)\nRemove rows where ‘type’ is “William Wyler” or NA and create a ‘cleaned_data’ subset: &gt;cleaned_data &lt;- rawdata %&gt;% &gt;&gt; filter(type != “William Wyler” & type != “Unknown” & !is.na(type))\nand then convert the ‘type’ variable into a factor: &gt;rawdata\\(type &lt;- as.factor(rawdata\\)type)\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  },
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch #to other formats, like html or pdf. See the Quarto documentation for other formats.*/\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "1.1 General Background Information",
    "text": "1.1 General Background Information\nThe intent of this analysis is to provide insights into how regional production practices and content types align with age rating distributions, offering valuable information for Netflix’s content acquisition and compliance strategies. This research highlights the importance of understanding content rating trends to better cater to diverse audiences and ensure appropriate content delivery."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "1.2 Description of data and data source",
    "text": "1.2 Description of data and data source\nData is on Netflix Movies and TV Shows from Kaggle.com site. The description says: “The Netflix Titles dataset is a comprehensive compilation of movies and TV shows available on Netflix, covering various aspects such as the title type, director, cast, country of production, release year, rating, duration, genres (listed in), and a brief description. This dataset is instrumental for analyzing trends in Netflix content, understanding genre popularity, and examining the distribution of content across different regions and time periods”\nThe dataset contains 8,809 observations and the following 12 variables:\n\nshow_id: A unique identifier for each title.\ntype: The category of the title, which is either ‘Movie’ or ‘TV Show’\ntitle: The name of the movie or TV show\ndirector: The director(s) of the movie or TV show (Contains null values for some entries, especially TV shows where this information might not be applicable)\ncast: The list of main actors/actresses in the title (Some entries might not have this information.)\ncountry: The country or countries where the movie or TV show was produced.\ndate_added: The date the title was added to Netflix.\nrelease_year: The year the movie or TV show was originally released.\nrating: The age rating of the title.\nduration: The duration of the title, in minutes for movies and seasons for TV shows\nlisted_in: The genres the title falls under.\ndescription: A brief summary of the title."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "1.3 Questions/Hypotheses to be addressed",
    "text": "1.3 Questions/Hypotheses to be addressed\nState the research questions you plan to answer with this analysis.\n“How do the type of content (Movie or TV Show) and the country of origin affect the distribution of age ratings on Netflix titles?”\nThis question focuses on understanding the relationship between content type, country of origin, and age ratings, which can provide valuable insights into regional production practices and content rating trends on Netflix\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the #bibtex file specified in the YAML header above (here dataanalysis_template_references.bib) and have the right bibtex key. #Then you can include like this:\nExamples of reproducible research projects can for instance be found in (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-acquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-acquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.1 Data Acquisition",
    "text": "2.1 Data Acquisition\nI imported the data for Netflix Movies and TV Shows which was available on Kaggle.com site. My raw data file is available through file path folders: starter-analysis-exercise &gt; data &gt; raw-data &gt; netflix_titles.xlsx"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.2 Data Import and Cleaning",
    "text": "2.2 Data Import and Cleaning\nThe file path to my code file for cleaning my dataset is: starter-analysis-exercise &gt; code &gt; processing-code &gt; processingfile\nFirst I imported the data…\n\n# Important\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\nhere are some of the initial cleaning techniques and a few reasons why I chose to do them:\n\nFor the country column, I filled missing values with the mode (most frequently occurring country).\nConverted the date_added to a Date format as a crucial step for any potential time series or date-related analysis.\nConverted type to a factor since I am planning on performing statistical tests and/or modeling that may need categorical input features.\n\n\n# Handling missing values\n\nrawdata$director[is.na(rawdata$director)] &lt;- \"Unknown\"\n\n# Fill missing 'country' values with the mode (most frequent value)\nmode_country &lt;- names(sort(table(rawdata$country), decreasing = TRUE))[1]\nrawdata$country[is.na(rawdata$country)] &lt;- mode_country\n\n# Safe conversion of date formats with error handling\nrawdata$date_added &lt;- as.Date(rawdata$date_added, format = \"%m/%d/%Y\")\nif(any(is.na(rawdata$date_added))) {\n  warning(\"There were errors in date conversion. Check date formats.\")\n}\n\nWarning: There were errors in date conversion. Check date formats.\n\n# Standardizing categorical variables\n\nrawdata$type &lt;- as.factor(rawdata$type)\n\n# Display the cleaned data\nhead(rawdata)\n\n# A tibble: 6 × 12\n  show_id type    title    director cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;fct&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;date&gt;            &lt;dbl&gt; &lt;chr&gt; \n1 s1      Movie   Dick Jo… Kirsten… &lt;NA&gt;  United… 2021-09-25         2020 PG-13 \n2 s2      TV Show Blood &… Unknown  Ama … South … 2021-09-24         2021 TV-MA \n3 s3      TV Show Ganglan… Julien … Sami… United… 2021-09-24         2021 TV-MA \n4 s4      TV Show Jailbir… Unknown  &lt;NA&gt;  United… 2021-09-24         2021 TV-MA \n5 s5      TV Show Kota Fa… Unknown  Mayu… India   2021-09-24         2021 TV-MA \n6 s6      TV Show Midnigh… Mike Fl… Kate… United… 2021-09-24         2021 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\nI also needed to do some clean up when it came to content ‘type’ as it included unwanted values…\n\n# Remove rows where 'type' is \"William Wyler\" or NA\ncleaned_data &lt;- rawdata[rawdata$type != \"William Wyler\" & rawdata$type != \"Unknown\" & !is.na(rawdata$type), ]\n\n\nsummary(cleaned_data)\n\n   show_id                     type         title             director        \n Length:8809        Movie        :6132   Length:8809        Length:8809       \n Class :character   TV Show      :2677   Class :character   Class :character  \n Mode  :character   William Wyler:   0   Mode  :character   Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n     cast             country            date_added          release_year \n Length:8809        Length:8809        Min.   :2008-01-01   Min.   :1925  \n Class :character   Class :character   1st Qu.:2018-04-06   1st Qu.:2013  \n Mode  :character   Mode  :character   Median :2019-07-02   Median :2017  \n                                       Mean   :2019-05-17   Mean   :2014  \n                                       3rd Qu.:2020-08-19   3rd Qu.:2019  \n                                       Max.   :2024-04-05   Max.   :2024  \n                                       NA's   :11           NA's   :1     \n    rating            duration          listed_in         description       \n Length:8809        Length:8809        Length:8809        Length:8809       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n\n\nWrite code that reads in the file and cleans it so it’s ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.3 Statistical Analysis",
    "text": "2.3 Statistical Analysis\nExplain anything related to your statistical analyses.\nThe relevant variables I’ll be using during my statistical analysis to determine how regional production practices and content types align with age rating distributions will be: Country, Type, and Rating.\nLet’s double check if there is any other missing data in my cleaned_data before I perform my analysis… nothing significant in 3 variables I’ll be using.\n\n# Calculate the number of missing values for each column in cleaned_data\nmissing_data_summary &lt;- sapply(cleaned_data, function(x) sum(is.na(x)))\n\n# Print the summary of missing data\nprint(missing_data_summary)\n\n     show_id         type        title     director         cast      country \n           0            0            0            0          825            0 \n  date_added release_year       rating     duration    listed_in  description \n          11            1            5            4            1            1 \n\n\nI also want to check for any outliers as well…\n\n# Create a boxplot for each numeric variable in the dataframe\nnumeric_vars &lt;- sapply(cleaned_data, is.numeric)\nif(any(numeric_vars)) {\n  # Filter only numeric columns\n  numeric_data &lt;- cleaned_data[, numeric_vars]\n\n  # Melt the data for easy plotting with ggplot2\n  library(reshape2)\n  long_data &lt;- melt(numeric_data)\n\n  # Plot\n  ggplot(long_data, aes(x = variable, y = value)) +\n    geom_boxplot(outlier.colour = \"red\", outlier.shape = 1) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(title = \"Boxplot for Each Numeric Variable\", x = \"Variables\", y = \"Values\")\n} else {\n  print(\"No numeric variables found for plotting.\")\n}\n\nWarning: package 'reshape2' was built under R version 4.3.3\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\nGiven my hypothesis, which aims to explore how the type of content (Movie or TV Show) and the country of origin influence the distribution of age ratings on Netflix titles, regression testing does not seem like the best testing method because I using 2 categorical variables (Type and Rating) as target variables. My ‘rating’ variable is not ordinal either which means we’d also leave out performing logistic regression.\nI believe the best testing methods in this case are either Chi-square (to test independence) or Multinomial Logistic Regression. MLR would be useful since the ‘Rating’ has multiple categories without order and would allow me to model the probability of each rating category as a function of ‘Type’ and ‘Country’.\nI will need install the following packages for the next part of my analysis\n\nlibrary(nnet)\nlibrary(forcats)\n\nInitially, when I ran the model it gave an error due to the complexity in the number of parameters it created based on the variations of categories I have in my variables. ChatGPT recommended I use the code below to create a decay term for regularization, which helps to manage the complexity of the model by shrinking the regression coefficients.\nWith the convergence of my multinomial logistic regression as indicated by “converged” in the output below, the next steps involve interpreting the model’s results and using them to validate my hypothesis or make further decisions.\n\n# Assuming 'Country' has many categories, we reduce them\ncleaned_data$country &lt;- fct_lump_n(cleaned_data$country, n = 10)  # Keeps the top 10 countries, others lumped into \"Other\"\ncleaned_data$country &lt;- factor(cleaned_data$country)\n\n# Fit the model with increased decay for regularization\n\nfit &lt;- multinom(type ~ country + rating, data = cleaned_data, MaxNWts = 10000, decay = 0.1)\n\nWarning in multinom(type ~ country + rating, data = cleaned_data, MaxNWts =\n10000, : group 'William Wyler' is empty\n\n\n# weights:  29 (28 variable)\ninitial  value 6102.467778 \niter  10 value 4551.137216\niter  20 value 4300.674269\niter  30 value 4276.943332\nfinal  value 4276.909270 \nconverged\n\n\nNow to run my multinomial model….\n\n# Ensure that 'Country', 'Type', and 'Rating' are factors\ncleaned_data$country &lt;- as.factor(cleaned_data$country)\ncleaned_data$type &lt;- as.factor(cleaned_data$type)\ncleaned_data$rating &lt;- as.factor(cleaned_data$rating)\n\n# Multinomial logistic regression\nmultinom_model &lt;- multinom(rating ~ country + type, data = cleaned_data)\n\n# weights:  252 (221 variable)\ninitial  value 25446.832957 \niter  10 value 18728.030041\niter  20 value 16906.955079\niter  30 value 15526.132442\niter  40 value 14980.668736\niter  50 value 14724.154902\niter  60 value 14656.735665\niter  70 value 14624.490886\niter  80 value 14615.654822\niter  90 value 14612.398803\niter 100 value 14611.228013\nfinal  value 14611.228013 \nstopped after 100 iterations\n\n# Summary of the model\nsummary(multinom_model)\n\nWarning in sqrt(diag(vc)): NaNs produced\n\n\nCall:\nmultinom(formula = rating ~ country + type, data = cleaned_data)\n\nCoefficients:\n         (Intercept) countryEgypt countryFrance countryIndia countryJapan\n74 min     -1.813493    2.9754275     0.3956199   -0.9714214   2.41979551\n84 min     -1.813493    2.9754275     0.3956199   -0.9714214   2.41979551\nA          -1.813493    2.9754275     0.3956199   -0.9714214   2.41979551\nG           5.117559   -3.6377154    -4.6556665   -5.1956130  -4.42089642\nNC-17       5.293475   -0.7285485    -5.1558932   -7.6811791  -3.91040508\nNR          5.969772   -2.3816946    -5.6716291    2.2264249  -4.66714238\nPG          7.389822   -7.7808417     0.8624780    0.1309791   2.68664023\nPG-13       6.411672   -4.3058335     1.8455658    1.7822731   3.37872073\nR           8.081236   -8.5606599     0.8652298   -1.2221487  -9.56543245\nTV-14       8.085485    9.1241640     2.6714935    4.9635913   3.86190160\nTV-G        7.430619    5.4642930     0.9222056    1.4958886  -0.08943671\nTV-MA       9.003829    7.3208905     3.1577765    3.2632319   3.01945227\nTV-PG       7.943574    6.3842254     0.8702201    3.6965706   3.19144246\nTV-Y        7.355051   -8.9476752     2.3120732    0.9286445   0.22410134\nTV-Y7       6.693138   -5.4072775     1.7538064    2.6024231   3.02469907\nTV-Y7-FV    5.172363   -0.8235049    -5.4307087    1.6013327  -4.59641820\nUR         -0.627117    2.4086825     8.8892483   -1.9515073   2.04209352\n         countryMexico countrySouth Korea countrySpain countryUnited Kingdom\n74 min       0.9730047          2.7803449    0.6678208             2.2538170\n84 min       0.9730047          2.7803449    0.6678208             2.2538170\nA            0.9730047          2.7803449    0.6678208             2.2538170\nG           -3.9125398         -2.9078780   -5.4229899            -5.8633005\nNC-17       -3.8296394         -3.0105907   -5.6584963            -5.0598829\nNR           5.0036247          4.9109376    3.4881020             2.9320343\nPG          -8.5179746         -8.1423723    2.1294223             0.7227442\nPG-13        3.2530670         -6.6138781    3.1111172             3.0830156\nR            2.9514864         -9.0589952    2.1359756             2.8242029\nTV-14        3.5870699          4.7420142    3.5198169             2.7279862\nTV-G         2.3579226          0.8890635    1.5689083             2.1964467\nTV-MA        4.5253938          3.9994634    4.8803234             2.8080144\nTV-PG        2.9887764          3.2667348    2.6958972             2.9379047\nTV-Y        -9.3982700          1.8656819    2.0737436             1.6912606\nTV-Y7        3.1197112          3.0544350  -10.4953965             0.9746520\nTV-Y7-FV    -4.0871792         -4.0443495   -5.8254463            -5.3494891\nUR           0.3953846          2.6887892   -0.1288406             1.4823803\n         countryUnited States countryOther typeTV Show typeWilliam Wyler\n74 min              2.4067979    1.6686629  -1.4146175                 0\n84 min              2.4067979    1.6686629  -1.4146175                 0\nA                   2.4067979    1.6686629  -1.4146175                 0\nG                  -1.1608910    2.8067915  -5.1637780                 0\nNC-17              -4.7285893    0.2156647  -2.7012113                 0\nNR                 -1.8744889    2.7914691   0.9037756                 0\nPG                 -1.6546214    2.7519333  -7.2607091                 0\nPG-13              -0.1178885    4.2800944  -6.9351304                 0\nR                  -1.3716861    3.1313741  -2.1930341                 0\nTV-14              -1.5872989    3.4023549   3.3427349                 0\nTV-G               -2.7097828    1.6531530   3.4271192                 0\nTV-MA              -1.7967268    3.1202129   3.1682250                 0\nTV-PG              -2.0547150    2.5757827   3.3006469                 0\nTV-Y               -2.5339954    1.8800122   4.0074045                 0\nTV-Y7              -1.7246375    2.4683118   4.0533445                 0\nTV-Y7-FV           -4.1470108    0.8800138   2.3830069                 0\nUR                  1.2439358    6.1830410  -2.8364490                 0\n\nStd. Errors:\n         (Intercept) countryEgypt countryFrance countryIndia countryJapan\n74 min      30.57980   1.94029326      88.62114     91.98723    58.969137\n84 min      30.57980   1.94029307      88.62114     91.98723    58.969137\nA           30.57980   1.94029309      88.62114     91.98723    58.969137\nG           11.16170   1.74214107      49.47545     37.25970    51.685059\nNC-17       11.15317  64.17328348      57.13409     97.41792    37.274176\nNR          11.13089  96.09485455      51.75340     20.97707    35.402617\nPG          11.11513   0.24626247      16.83676     20.97465     9.579189\nPG-13       11.12405   3.59431522      16.84204     20.97359     9.592387\nR           11.11243   0.22528698      16.82166     20.98391     3.337291\nTV-14       11.11153  23.27198345      16.80902     20.96149     9.564357\nTV-G        11.11309  23.28856090      16.82217     20.96475     9.612998\nTV-MA       11.11054  23.27194785      16.80747     20.96103     9.563317\nTV-PG       11.11182  23.27581459      16.81692     20.96176     9.565332\nTV-Y        11.11272   0.09613832      16.81120     20.96650     9.588898\nTV-Y7       11.11502   1.91906075      16.81878     20.96480     9.570199\nTV-Y7-FV    11.15170  68.57210422      61.20427     21.00476    39.822617\nUR          21.70212   2.73885482      24.67119    106.23259    40.817253\n         countryMexico countrySouth Korea countrySpain countryUnited Kingdom\n74 min       17.074236          88.058968    12.019499             41.377546\n84 min       17.074236          88.058968    12.019499             41.377546\nA            17.074236          88.058968    12.019499             41.377545\nG            65.984342          49.655114    57.939375             55.896332\nNC-17        58.794986          47.841753    47.815996             35.156970\nNR           19.621310          14.932895    24.094837              8.687812\nPG            9.387653           2.540646    24.088186              8.684983\nPG-13        19.634169           5.659216    24.091799              8.676006\nR            19.612109           1.960626    24.078070              8.657815\nTV-14        19.607785          14.910581    24.070186              8.655850\nTV-G         19.617579          14.940880    24.087605              8.659077\nTV-MA        19.605865          14.909888    24.068534              8.654282\nTV-PG        19.609841          14.912261    24.072615              8.656139\nTV-Y          8.884822          14.918331    24.078332              8.659104\nTV-Y7        19.615442          14.916695     1.193296              8.669398\nTV-Y7-FV     62.405980          52.188577    37.904614             34.897954\nUR          115.113183          55.769537    19.949580             31.851655\n         countryUnited States countryOther typeTV Show typeWilliam Wyler\n74 min               30.62111     37.95124   15.054802      1.114630e-07\n84 min               30.62111     37.95124   15.054802               NaN\nA                    30.62111     37.95124   15.054802               NaN\nG                    11.23602     18.89397   15.773212               NaN\nNC-17                11.27180     18.91371   17.299287               NaN\nNR                   11.20511     18.87443    8.361214      3.600569e-10\nPG                   11.18848     18.86445   16.514523      2.594444e-10\nPG-13                11.19722     18.86957   12.506672      1.625364e-11\nR                    11.18563     18.86269    8.375807      1.940496e-13\nTV-14                11.18471     18.86211    8.348343      1.369635e-13\nTV-G                 11.18648     18.86341    8.349333      3.937205e-14\nTV-MA                11.18369     18.86151    8.348272      4.859999e-14\nTV-PG                11.18504     18.86235    8.348512      1.805119e-14\nTV-Y                 11.18596     18.86301    8.348988               NaN\nTV-Y7                11.18818     18.86437    8.348937      3.564171e-26\nTV-Y7-FV             11.24518     18.89770    8.421118      0.000000e+00\nUR                   21.76174     26.49253   17.536564      0.000000e+00\n\nResidual Deviance: 29222.46 \nAIC: 29630.46 \n\n# To get probabilities\nprobabilities &lt;- predict(multinom_model, type = \"probs\")\n\n# Viewing the first few rows of probabilities\nhead(probabilities)\n\n        66 min       74 min       84 min            A            G        NC-17\n1 2.197696e-04 3.977743e-04 3.977743e-04 3.977743e-04 1.149018e-02 3.866288e-04\n2 1.046572e-07 2.200441e-08 2.200441e-08 2.200441e-08 1.654515e-06 1.734750e-06\n3 1.258220e-05 5.534332e-06 5.534332e-06 5.534332e-06 3.762838e-06 1.485806e-06\n4 1.258220e-05 5.534332e-06 5.534332e-06 5.534332e-06 3.762838e-06 1.485806e-06\n5 4.468941e-08 6.704574e-10 6.704574e-10 6.704574e-10 2.364318e-10 2.754968e-10\n6 1.258220e-05 5.534332e-06 5.534332e-06 5.534332e-06 3.762838e-06 1.485806e-06\n            NR           PG        PG-13            R     TV-14       TV-G\n1 0.0131985545 6.803521e-02 1.189387e-01 1.802553e-01 0.1459130 0.02467179\n2 0.0016490449 1.866344e-06 4.479769e-06 8.648112e-04 0.2888059 0.02839096\n3 0.0018656069 2.736761e-06 6.625572e-06 1.151475e-03 0.2363820 0.04348793\n4 0.0018656069 2.736761e-06 6.625572e-06 1.151475e-03 0.2363820 0.04348793\n5 0.0004001956 5.796439e-08 1.573624e-07 4.749477e-06 0.5875946 0.01035897\n6 0.0018656069 2.736761e-06 6.625572e-06 1.151475e-03 0.2363820 0.04348793\n      TV-MA     TV-PG        TV-Y      TV-Y7     TV-Y7-FV           UR\n1 0.2964644 0.0793353 0.027272531 0.03160530 0.0006127349 4.072383e-04\n2 0.4582647 0.1051285 0.059006494 0.05739596 0.0004821809 1.587896e-06\n3 0.4033705 0.1232277 0.085883178 0.10420632 0.0003801792 1.367047e-06\n4 0.4033705 0.1232277 0.085883178 0.10420632 0.0003801792 1.367047e-06\n5 0.2257690 0.1376917 0.009731089 0.02802596 0.0004235554 1.988237e-10\n6 0.4033705 0.1232277 0.085883178 0.10420632 0.0003801792 1.367047e-06"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Exploratory/Descriptive Analysis",
    "text": "3.1 Exploratory/Descriptive Analysis\nDistribution between Movies and TV Shows:\n\n# Perform the group_by and summarise operations\ntype_distribution &lt;- aggregate(. ~ type, data = cleaned_data, FUN = length)\nnames(type_distribution)[2] &lt;- \"count\"\n\n# Plot the distribution of content types\nbarplot(height = type_distribution$count,\n        names.arg = type_distribution$type,\n        col = c(\"purple\", \"orange\"),\n        main = \"Distribution of Content Types - Movies v TV Shows\",\n        xlab = \"Type\",\n        ylab = \"Count\",\n        las = 1) # las = 1 makes axis labels horizontal\n\n\n\n\nWe see from the distribution that it appears movies are being streamed substantially more than TV shows, but to get a better sense of this let’s represent it as a percentage instead\n\ntype_distribution &lt;- aggregate(. ~ type, data = cleaned_data, FUN = length)\nnames(type_distribution)[2] &lt;- \"count\"\n\ntype_distribution$percentage &lt;- round((type_distribution$count / sum(type_distribution$count)) * 100, 1)\n\nlabels &lt;- paste(type_distribution$type, type_distribution$percentage, \"%\")\n\npie(type_distribution$count,\n    labels = labels,\n    col = c(\"purple\", \"orange\"),\n    main = \"Percentage of Movies vs TV Shows\")\n\n\n\n\nNow I’d like to see which countries the Movie/TV show content originate from\n\nlibrary(ggplot2)\n\ncountry_counts &lt;- head(sort(table(cleaned_data$country), decreasing = TRUE), 10)\n\n# Convert to data frame for ggplot\ncountry_df &lt;- data.frame(\n  country = names(country_counts),\n  count = as.numeric(country_counts)\n)\n\n# Create the bar chart\np &lt;- ggplot(country_df, aes(x = reorder(country, -count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"purple\") +\n  geom_text(aes(label = count), vjust = -0.3) +\n  labs(x = \"Country\", y = \"Count\", title = \"Top 10 Countries (Top 3 Highlighted)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_bar(data = country_df[1:3, ], aes(x = country, y = count), stat = \"identity\", fill = \"orange\")\n\nprint(p)\n\n\n\n\nLet’s see the distribution of ratings:\n\n# Plot the distribution of ratings\nggplot(cleaned_data, aes(x = rating)) +\n  geom_bar(fill = \"#4E79A7\") +\n  labs(title = \"Distribution of Ratings\",\n       x = \"Rating\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n# Split the 'listed_in' column into individual genres\ngenres &lt;- unlist(strsplit(cleaned_data$listed_in, \", \"))\ngenre_table &lt;- as.data.frame(table(genres))\n\n# Arrange by frequency in descending order and select top 10\ngenre_counts &lt;- genre_table[order(-genre_table$Freq), ]\ngenre_counts &lt;- genre_counts[1:10, ]\n\n# Plot the top 10 genres\nlibrary(ggplot2)\n\n# Plotting the bar chart\nggplot(data = genre_counts, aes(x = reorder(genres, Freq), y = Freq)) +\n  geom_bar(stat = \"identity\", fill = \"#4E79A7\") +\n  geom_text(aes(label = Freq), \n            position = position_stack(vjust = 0.5), \n            color = \"white\", \n            size = 4, \n            family = \"sans\") +  # Adjust position and styling of labels\n  labs(title = \"Top 10 Genres\",\n       x = \"Genre\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10, family = \"sans\")) +  # Rotate x-axis labels\n  theme_minimal()\n\n\n\n\nGiven that Netflix launched at the end of August in 1997 as a DVD rental service this distribution makes sense:\n\n# Plot the count of titles by release year\nggplot(cleaned_data, aes(x = release_year)) +\n  geom_histogram(binwidth = 1, fill = \"#4E79A7\", color = \"white\") +\n  labs(title = \"Count of Titles by Release Year\",\n       x = \"Release Year\", y = \"Count\") +\n  theme_minimal()\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n# Count occurrences of each country and type\ncount_data &lt;- count(cleaned_data, country, type)\n\n# Group by country\ngrouped_data &lt;- group_by(count_data, country)\n\n# Calculate percentage within each group\ngrouped_data &lt;- mutate(grouped_data, percentage = n / sum(n) * 100)\n\n# Ungroup the data\npercentage_data &lt;- ungroup(grouped_data)\n\n# Show percentage_data\npercentage_data\n\n# A tibble: 22 × 4\n   country type        n percentage\n   &lt;fct&gt;   &lt;fct&gt;   &lt;int&gt;      &lt;dbl&gt;\n 1 Canada  Movie     122      67.4 \n 2 Canada  TV Show    59      32.6 \n 3 Egypt   Movie      92      86.8 \n 4 Egypt   TV Show    14      13.2 \n 5 France  Movie      75      60.5 \n 6 France  TV Show    49      39.5 \n 7 India   Movie     893      91.9 \n 8 India   TV Show    79       8.13\n 9 Japan   Movie      76      31.0 \n10 Japan   TV Show   169      69.0 \n# ℹ 12 more rows\n\n\n\n# Calculate total count of each country\ncountry_totals &lt;- aggregate(percentage_data$n, by = list(percentage_data$country), FUN = sum)\n\n# Select top 10 countries by total count\ntop_10_countries &lt;- country_totals[order(country_totals$x, decreasing = TRUE), ]$Group.1[1:10]\n\n# Subset data for top 10 countries only\ntop_10_data &lt;- subset(percentage_data, country %in% top_10_countries)\n\n# Create pie chart for top 10 countries with improved readability\nlibrary(ggplot2)\n\n# Plotting the pie chart\npie_plot &lt;- ggplot(top_10_data, aes(x = \"\", y = n, fill = type)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(theta = \"y\") +\n  facet_wrap(~ country, scales = \"free_y\") +\n  geom_text(aes(label = paste0(round(percentage, 2), \"%\")),\n            position = position_stack(vjust = 0.5), color = \"white\", size = 4, family = \"sans\") +  # Adjust text size, color, and font family\n  theme_void() +\n  scale_fill_manual(values = c(\"#5E81AC\", \"#E19C24\"), labels = c(\"Movie\", \"TV Show\")) +  # Adjust colors and labels\n  theme(legend.position = \"bottom\", legend.text = element_text(size = 10, family = \"sans\"), plot.title = element_text(hjust = 0.5, size = 14, family = \"sans\")) +  # Adjust legend and title text\n  labs(fill = \"Type\", title = \"Percentage of Movies vs TV Shows in Top 10 Countries\")  # Adjust title\n\n# Show the plot\nprint(pie_plot)\n\n\n\n\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\nTable 1 shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I recommend the here package, but I’m showing the other approach here just in case you encounter it.\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nfactor.ordered\nfactor.n_unique\nfactor.top_counts\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\nfactor\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nHeight\n0\n1\nNA\nNA\nNA\n165.66667\n15.97655\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nnumeric\nWeight\n0\n1\nNA\nNA\nNA\n70.11111\n21.24526\n45\n55\n70\n80\n110\n▇▂▃▂▂"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Basic Statistical Analysis",
    "text": "3.2 Basic Statistical Analysis\nTo get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any “p&lt;0.05 means statistical significance” interpretation is not valid.\nThe following code below calculates p-values for the coefficients of a multinomial logistic regression model (created in section above on “Statistical Analysis”) and prints these values. The model was fit to predict the rating of Netflix titles based on the country and type (Movie or TV Show).\n\nmodel &lt;- nnet::multinom(rating ~ country + type, data = cleaned_data)\n\n# weights:  252 (221 variable)\ninitial  value 25446.832957 \niter  10 value 18728.030041\niter  20 value 16906.955079\niter  30 value 15526.132442\niter  40 value 14980.668736\niter  50 value 14724.154902\niter  60 value 14656.735665\niter  70 value 14624.490886\niter  80 value 14615.654822\niter  90 value 14612.398803\niter 100 value 14611.228013\nfinal  value 14611.228013 \nstopped after 100 iterations\n\n# Summary of the model to get coefficients and standard errors\nmodel_summary &lt;- summary(model)\n\nWarning in sqrt(diag(vc)): NaNs produced\n\n# Calculate z-values\nz_values &lt;- coef(model_summary) / model_summary$standard.errors\n\n# Get p-values from z-values\np_values &lt;- 2 * pnorm(abs(z_values), lower.tail = FALSE)\n\n# View the p-values\nprint(p_values)\n\n         (Intercept)  countryEgypt countryFrance countryIndia countryJapan\n74 min     0.9527103  1.251543e-01     0.9964381    0.9915742  0.967268034\n84 min     0.9527103  1.251542e-01     0.9964381    0.9915742  0.967268034\nA          0.9527103  1.251542e-01     0.9964381    0.9915742  0.967268034\nG          0.6465984  3.679137e-02     0.9250293    0.8890999  0.931835842\nNC-17      0.6350607  9.909419e-01     0.9280949    0.9371538  0.916447836\nNR         0.5917341  9.802266e-01     0.9127349    0.9154743  0.895118413\nPG         0.5061506 4.226356e-219     0.9591455    0.9950175  0.779119731\nPG-13      0.5643587  2.309339e-01     0.9127417    0.9322797  0.724666236\nR          0.4670884  0.000000e+00     0.9589785    0.9535557  0.004153972\nTV-14      0.4668180  6.950091e-01     0.8737224    0.8128152  0.686374080\nTV-G       0.5037274  8.144927e-01     0.9562812    0.9431172  0.992576807\nTV-MA      0.4177180  7.530805e-01     0.8509713    0.8762846  0.752205374\nTV-PG      0.4746858  7.838650e-01     0.9587305    0.8600203  0.738646096\nTV-Y       0.5080617  0.000000e+00     0.8906105    0.9646718  0.981354403\nTV-Y7      0.5470605  4.837368e-03     0.9169498    0.9012100  0.751961564\nTV-Y7-FV   0.6427779  9.904182e-01     0.9292958    0.9392308  0.908110401\nUR         0.9769471  3.791580e-01     0.7186162    0.9853436  0.960098358\n         countryMexico countrySouth Korea countrySpain countryUnited Kingdom\n74 min       0.9545558       9.748120e-01 9.556912e-01             0.9565611\n84 min       0.9545558       9.748120e-01 9.556912e-01             0.9565611\nA            0.9545558       9.748120e-01 9.556912e-01             0.9565611\nG            0.9527172       9.533014e-01 9.254288e-01             0.9164583\nNC-17        0.9480661       9.498238e-01 9.057991e-01             0.8855616\nNR           0.7987156       7.422562e-01 8.848960e-01             0.7357489\nPG           0.3642168       1.351362e-03 9.295579e-01             0.9336785\nPG-13        0.8684057       2.425279e-01 8.972501e-01             0.7223277\nR            0.8803756       3.828882e-06 9.293121e-01             0.7442710\nTV-14        0.8548442       7.504621e-01 8.837387e-01             0.7526394\nTV-G         0.9043292       9.525495e-01 9.480678e-01             0.7997596\nTV-MA        0.8174559       7.885128e-01 8.393165e-01             0.7455858\nTV-PG        0.8788619       8.266004e-01 9.108312e-01             0.7343074\nTV-Y         0.2901515       9.004763e-01 9.313671e-01             0.8451457\nTV-Y7        0.8736345       8.377548e-01 1.426641e-18             0.9104869\nTV-Y7-FV     0.9477812       9.382298e-01 8.778565e-01             0.8781700\nUR           0.9972595       9.615469e-01 9.948470e-01             0.9628797\n         countryUnited States countryOther typeTV Show typeWilliam Wyler\n74 min              0.9373513    0.9649294   0.9251373                 1\n84 min              0.9373513    0.9649294   0.9251373               NaN\nA                   0.9373513    0.9649294   0.9251373               NaN\nG                   0.9177101    0.8819049   0.7433832               NaN\nNC-17               0.6748462    0.9909023   0.8759181               NaN\nNR                  0.8671429    0.8824241   0.9139232                 1\nPG                  0.8824326    0.8840166   0.6601863                 1\nPG-13               0.9915997    0.8205597   0.5792268                 1\nR                   0.9024007    0.8681500   0.7934528                 1\nTV-14               0.8871456    0.8568540   0.6888568                 1\nTV-G                0.8085963    0.9301643   0.6814640                 1\nTV-MA               0.8723643    0.8686075   0.7043117                 1\nTV-PG               0.8542472    0.8913811   0.6925791                 1\nTV-Y                0.8207864    0.9206090   0.6312367               NaN\nTV-Y7               0.8774929    0.8958978   0.6273272                 1\nTV-Y7-FV            0.7122907    0.9628581   0.7771923               NaN\nUR                  0.9544165    0.8154601   0.8715068               NaN\n\n\nInterpretation of the output above:\nEach row in your output corresponds to a different rating category’s model coefficients for the predictors country and type.\np-values for each coefficient tell you whether the effect of that predictor (e.g., country= France or type= TV Show) on the likelihood of a Netflix title having a particular rating is statistically significant.\nSignificant p-values (typically &lt; 0.05) indicate that the corresponding coefficient significantly affects the rating category, adjusting for other factors in the model.\nFor instance, if the country of Mexico has a p-value less than 0.05 for the rating ‘NR’, it means that being from Mexico is a significant predictor of a title having an ‘NR’ rating compared to the baseline rating category, given all other factors constant.\nCoefficients with large p-values suggest that those variables do not significantly predict the rating outcome when controlling for other variables.\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\nFigure 1: Height and weight stratified by gender."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Full Analysis",
    "text": "3.3 Full Analysis\nUse one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n149.2726967\n23.3823360\n6.3839942\n0.0013962\n\n\nWeight\n0.2623972\n0.3512436\n0.7470519\n0.4886517\n\n\nGenderM\n-2.1244913\n15.5488953\n-0.1366329\n0.8966520\n\n\nGenderO\n-4.7644739\n19.0114155\n-0.2506112\n0.8120871"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Summary and Interpretation",
    "text": "4.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Strengths and Limitations",
    "text": "4.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Conclusions",
    "text": "4.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, et al., 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word references.bib but giving it a more descriptive name is probably better."
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Holly Milazzo Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  }
]