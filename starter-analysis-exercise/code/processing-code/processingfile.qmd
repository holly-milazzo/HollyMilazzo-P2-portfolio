---
title: "An example cleaning script"
author: "Holly Milazzo"
date: "2024-06-13"
output: html_document
---


# Processing script

This Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.


# Setup

Load needed packages. make sure they are installed.

```{r}
library(readxl) #for loading Excel files
library(ggplot2)
library(dplyr) #for data processing/cleaning
library(tidyr) #for data processing/cleaning
library(skimr) #for nice visualization of data 
library(here) #to set paths
```


# Data loading

Note that for functions that come from specific packages (instead of base R), I often specify both package and function like so:
package::function() that's not required one could just call the function specifying the package makes it clearer where the function "lives",
but it adds typing. You can do it either way.

```{r}
# path to data
# note the use of the here() package and not absolute paths
data_location <- here::here("starter-analysis-exercise","data","raw-data","exampledata.xlsx")
rawdata <- readxl::read_excel(data_location)
```

```{r}
head(rawdata)
```



# Check data

Several ways of looking at the data

```{r}
dplyr::glimpse(rawdata)
summary(rawdata)
head(rawdata)
skimr::skim(rawdata)
```



# Cleaning

By inspecting the data as done above, we find some problems that need addressing:

First, there is an entry for height which says "sixty" instead of a number. 
Does that mean it should be a numeric 60? It somehow doesn't make sense since the weight is 60kg, which can't happen for a 60cm person (a baby).
Since we don't know how to fix this, we might decide to remove the person. This "sixty" entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn't very meaningful. So let's fix that first.

```{r}
# Handling missing values
rawdata$director[is.na(rawdata$director)] <- "Unknown"

# Converting date formats
rawdata$date_added <- as.Date(rawdata$date_added, format = "%m/%d/%Y")

# Standardizing categorical variables
rawdata$type <- as.factor(rawdata$type)

# Convert 'type' back to factor after mutation
rawdata$type <- as.factor(rawdata$type)

# Display the cleaned data
head(rawdata)
```
```{r}
# Remove rows where 'type' is "William Wyler" or NA
cleaned_data <- rawdata %>%
  filter(type != "William Wyler" & type != "Unknown" & !is.na(type))

head(cleaned_data)

```

creating a bar graph of the countries
```{r}
country_counts <- head(sort(table(cleaned_data$country), decreasing = TRUE), 10)

# Convert to data frame for ggplot
country_df <- data.frame(
  country = names(country_counts),
  count = as.numeric(country_counts)
)

# Create the bar chart
p <- ggplot(country_df, aes(x = reorder(country, -count), y = count)) +
  geom_bar(stat = "identity", fill = "blue") +
  geom_text(aes(label = count), vjust = -0.3) +
  labs(x = "Country", y = "Count", title = "Top 10 Countries (Top 3 Highlighted)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_bar(data = country_df[1:3, ], aes(x = country, y = count), stat = "identity", fill = "red")

# Display the plot
print(p)
```





# Save data 

Finally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. 
This preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.
However, CSV is better for sharing with others since it's plain text. If you do CSV, you might want to write down somewhere what each variable is.

See here for some suggestions on how to store your processed data:
http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata

```{r}
save_data_location <- here::here("starter-analysis-exercise","data","processed-data","cleaned_data.rds")
saveRDS(cleaned_data, file = save_data_location)
```

Note the use of the `here` package and `here` command to specify a path relative to the main project directory, that is the folder that contains the `.Rproj` file. Always use this approach instead of hard-coding file paths that only exist on your computer.



# Notes

Removing anyone observation with "faulty" or missing data is one approach. It's often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information).



