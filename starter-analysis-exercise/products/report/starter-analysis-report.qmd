---
title: "Manuscript/Report Template for a Data Analysis Project"
subtitle: ""
author: Holly Milazzo
date: today
format:
  html:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../dataanalysis-template-references.bib
csl: ../apa.csl
editor: 
  markdown: 
    wrap: sentence
---

The structure below is one possible setup for a data analysis project (including the course project).
For a manuscript, adjust as needed.
You don't need to have exactly these sections, but the content covering those sections should be addressed.

This uses MS Word as output format.
[See here](https://quarto.org/docs/output-formats/ms-word.html) for more information.
You can switch #to other formats, like html or pdf.
See [the Quarto documentation](https://quarto.org/) for other formats.\*/

```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
library(dplyr)
library(ggplot2)
```

# Summary/Abstract

This study explores the hypothesis that the type of content (Movie or TV Show) and the country of origin influence the distribution of age ratings assigned to Netflix titles.
Utilizing a detailed dataset containing information about Netflix titles, we conduct an extensive analysis involving data cleaning, exploratory data analysis, and statistical testing.

{{< pagebreak >}}

## General Background Information

The intent of this analysis is to provide insights into how regional production practices and content types align with age rating distributions, offering valuable information for Netflix's content acquisition and compliance strategies.
This research highlights the importance of understanding content rating trends to better cater to diverse audiences and ensure appropriate content delivery.

## Description of data and data source

Data is on Netflix Movies and TV Shows from Kaggle.com site.
The description says: "The Netflix Titles dataset is a comprehensive compilation of movies and TV shows available on Netflix, covering various aspects such as the title type, director, cast, country of production, release year, rating, duration, genres (listed in), and a brief description. This dataset is instrumental for analyzing trends in Netflix content, understanding genre popularity, and examining the distribution of content across different regions and time periods"

The dataset contains 8,809 observations and the following 12 variables:

-   **show_id:** A unique identifier for each title.

-   **type:** The category of the title, which is either 'Movie' or 'TV Show'

-   **title:** The name of the movie or TV show

-   **director:** The director(s) of the movie or TV show (Contains null values for some entries, especially TV shows where this information might not be applicable)

-   **cast:** The list of main actors/actresses in the title (Some entries might not have this information.)

-   **country:** The country or countries where the movie or TV show was produced.

-   **date_added:** The date the title was added to Netflix.

-   **release_year:** The year the movie or TV show was originally released.

-   **rating:** The age rating of the title.

-   **duration:** The duration of the title, in minutes for movies and seasons for TV shows

-   **listed_in:** The genres the title falls under.

-   **description:** A brief summary of the title.

## Questions/Hypotheses to be addressed

*State the research questions you plan to answer with this analysis.*

"How do the type of content (Movie or TV Show) and the country of origin affect the distribution of age ratings on Netflix titles?"

This question focuses on understanding the relationship between content type, country of origin, and age ratings, which can provide valuable insights into regional production practices and content rating trends on Netflix

To cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the #bibtex file specified in the YAML header above (here `dataanalysis_template_references.bib`) and have the right bibtex key.
#Then you can include like this:

Examples of reproducible research projects can for instance be found in [@mckay2020; @mckay2020a]

{{< pagebreak >}}

# Methods

*Describe your methods. That should describe the data, the cleaning processes, and the analysis approaches. You might want to provide a shorter description here and all the details in the supplement.*

I will be using EDA initially and from there branching out into some hypothesis testing using Multinomial Logistic Regression to see if there is any association between country, content type, and rating.

## Data Acquisition

I imported the data for Netflix Movies and TV Shows which was available on Kaggle.com site.
My raw data file is available through file path folders: starter-analysis-exercise \> data \> raw-data \> netflix_titles.xlsx

## Data Import and Cleaning

The file path to my code file for cleaning my dataset is: starter-analysis-exercise \> code \> processing-code \> processingfile

First I imported the data...

```{r}
# Important
data_location <- here::here("starter-analysis-exercise","data","raw-data","exampledata.xlsx")
rawdata <- readxl::read_excel(data_location)
```

here are some of the initial cleaning techniques and a few reasons why I chose to do them:

-   For the country column, I filled missing values with the mode (most frequently occurring country).

-   Converted the date_added to a Date format as a crucial step for any potential time series or date-related analysis.

-   Converted type to a factor since I am planning on performing statistical tests and/or modeling that may need categorical input features.

```{r}
# Handling missing values

rawdata$director[is.na(rawdata$director)] <- "Unknown"

# Fill missing 'country' values with the mode (most frequent value)
mode_country <- names(sort(table(rawdata$country), decreasing = TRUE))[1]
rawdata$country[is.na(rawdata$country)] <- mode_country

# Safe conversion of date formats with error handling
rawdata$date_added <- as.Date(rawdata$date_added, format = "%m/%d/%Y")
if(any(is.na(rawdata$date_added))) {
  warning("There were errors in date conversion. Check date formats.")
}

# Standardizing categorical variables

rawdata$type <- as.factor(rawdata$type)

# Display the cleaned data
head(rawdata)
```

I also needed to do some clean up when it came to content 'type' as it included unwanted values...

```{r}
# Remove rows where 'type' is "William Wyler" or NA
cleaned_data <- rawdata[rawdata$type != "William Wyler" & rawdata$type != "Unknown" & !is.na(rawdata$type), ]


```

```{r}
summary(cleaned_data)
```

*Write code that reads in the file and cleans it so it's ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along.*

## Statistical Analysis

*Explain anything related to your statistical analyses.*

The relevant variables I'll be using during my statistical analysis to determine how regional production practices and content types align with age rating distributions will be: Country, Type, and Rating.

Let's double check if there is any other missing data in my cleaned_data before I perform my analysis... nothing significant in 3 variables I'll be using.

```{r}
# Calculate the number of missing values for each column in cleaned_data
missing_data_summary <- sapply(cleaned_data, function(x) sum(is.na(x)))

# Print the summary of missing data
print(missing_data_summary)

```

I also want to check for any outliers as well...

```{r, message=FALSE}
# Create a boxplot for each numeric variable in the dataframe
numeric_vars <- sapply(cleaned_data, is.numeric)
if(any(numeric_vars)) {
  # Filter only numeric columns
  numeric_data <- cleaned_data[, numeric_vars]

  # Melt the data for easy plotting with ggplot2
  library(reshape2)
  long_data <- melt(numeric_data)

  # Plot
  ggplot(long_data, aes(x = variable, y = value)) +
    geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Boxplot for Each Numeric Variable", x = "Variables", y = "Values")
} else {
  print("No numeric variables found for plotting.")
}
```

Given my hypothesis, which aims to explore how the type of content (Movie or TV Show) and the country of origin influence the distribution of age ratings on Netflix titles, regression testing does not seem like the best testing method because I using 2 categorical variables (Type and Rating) as target variables.
My 'rating' variable is not ordinal either which means we'd also leave out performing logistic regression.

I believe the best testing methods in this case are either Chi-square (to test independence) or Multinomial Logistic Regression.
MLR would be useful since the 'Rating' has multiple categories without order and would allow me to model the probability of each rating category as a function of 'Type' and 'Country'.

I will need install the following packages for the next part of my analysis

```{r}
library(nnet)
library(forcats)
```

Initially, when I ran the model it gave an error due to the complexity in the number of parameters it created based on the variations of categories I have in my variables.
ChatGPT recommended I use the code below to create a decay term for regularization, which helps to manage the complexity of the model by shrinking the regression coefficients.

With the convergence of my multinomial logistic regression as indicated by "converged" in the output below, the next steps involve interpreting the model's results and using them to validate my hypothesis or make further decisions.

```{r}
# Assuming 'Country' has many categories, we reduce them
cleaned_data$country <- fct_lump_n(cleaned_data$country, n = 10)  # Keeps the top 10 countries, others lumped into "Other"
cleaned_data$country <- factor(cleaned_data$country)

# Fit the model with increased decay for regularization

fit <- multinom(type ~ country + rating, data = cleaned_data, MaxNWts = 10000, decay = 0.1)

```

Now to run my multinomial model....

```{r}
# Ensure that 'Country', 'Type', and 'Rating' are factors
cleaned_data$country <- as.factor(cleaned_data$country)
cleaned_data$type <- as.factor(cleaned_data$type)
cleaned_data$rating <- as.factor(cleaned_data$rating)

# Multinomial logistic regression
multinom_model <- multinom(rating ~ country + type, data = cleaned_data)

# Summary of the model
summary(multinom_model)

# To get probabilities
probabilities <- predict(multinom_model, type = "probs")

# Viewing the first few rows of probabilities
head(probabilities)
```

{{< pagebreak >}}

# Results

Interpretation of Multinomial Logistic Regression model results

The results from the MLR provided a complex but informative view into how different countries and types of content (e.g., Movies vs. TV Shows) relate to the ratings of Netflix titles.
Here's a breakdown and interpretation of the results:

The model successfully converged after 100 iterations, indicating that the algorithm was able to find a stable solution.
The final value (14611.228013) of the deviance indicates the fit of the model to my data.

The coefficients for each level of the factors (Country, Type) show how each category relates to the probability of the content having a specific rating compared to the baseline category, however, without knowing the standard errors or p-values it's challenging to discuss the statistical significance of each coefficient - only the magnitude and direction (positive or negative) of the coefficients can provide insights at this point.

## Exploratory/Descriptive Analysis

Distribution between Movies and TV Shows:

```{r}
# Perform the group_by and summarise operations
type_distribution <- aggregate(. ~ type, data = cleaned_data, FUN = length)
names(type_distribution)[2] <- "count"

# Plot the distribution of content types
barplot(height = type_distribution$count,
        names.arg = type_distribution$type,
        col = c("purple", "orange"),
        main = "Distribution of Content Types - Movies v TV Shows",
        xlab = "Type",
        ylab = "Count",
        las = 1) # las = 1 makes axis labels horizontal
```

We see from the distribution that it appears movies are being streamed substantially more than TV shows, but to get a better sense of this let's represent it as a percentage instead

```{r}
type_distribution <- aggregate(. ~ type, data = cleaned_data, FUN = length)
names(type_distribution)[2] <- "count"

type_distribution$percentage <- round((type_distribution$count / sum(type_distribution$count)) * 100, 1)

labels <- paste(type_distribution$type, type_distribution$percentage, "%")

pie(type_distribution$count,
    labels = labels,
    col = c("purple", "orange"),
    main = "Percentage of Movies vs TV Shows")
```

Now I'd like to see which countries the Movie/TV show content originate from

```{r}
library(ggplot2)

country_counts <- head(sort(table(cleaned_data$country), decreasing = TRUE), 10)

# Convert to data frame for ggplot
country_df <- data.frame(
  country = names(country_counts),
  count = as.numeric(country_counts)
)

# Create the bar chart
p <- ggplot(country_df, aes(x = reorder(country, -count), y = count)) +
  geom_bar(stat = "identity", fill = "purple") +
  geom_text(aes(label = count), vjust = -0.3) +
  labs(x = "Country", y = "Count", title = "Top 10 Countries (Top 3 Highlighted)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_bar(data = country_df[1:3, ], aes(x = country, y = count), stat = "identity", fill = "orange")

print(p)
```

```{}
```

```{r}
# Split the 'listed_in' column into individual genres
genres <- unlist(strsplit(cleaned_data$listed_in, ", "))
genre_table <- as.data.frame(table(genres))

# Arrange by frequency in descending order and select top 10
genre_counts <- genre_table[order(-genre_table$Freq), ]
genre_counts <- genre_counts[1:10, ]

# Plot the top 10 genres
library(ggplot2)

# Plotting the bar chart
ggplot(data = genre_counts, aes(x = reorder(genres, Freq), y = Freq)) +
  geom_bar(stat = "identity", fill = "#4E79A7") +
  geom_text(aes(label = Freq), 
            position = position_stack(vjust = 0.5), 
            color = "white", 
            size = 4, 
            family = "sans") +  # Adjust position and styling of labels
  labs(title = "Top 10 Genres",
       x = "Genre", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10, family = "sans")) +  # Rotate x-axis labels
  theme_minimal()
```

Given that Netflix launched at the end of August in 1997 as a DVD rental service this distribution makes sense:

```{r}
# Plot the count of titles by release year
ggplot(cleaned_data, aes(x = release_year)) +
  geom_histogram(binwidth = 1, fill = "#4E79A7", color = "white") +
  labs(title = "Count of Titles by Release Year",
       x = "Release Year", y = "Count") +
  theme_minimal()
```

Let's also explore what the content consumption is like between countries...

```{r}
# Count occurrences of each country and type
count_data <- count(cleaned_data, country, type)

# Group by country
grouped_data <- group_by(count_data, country)

# Calculate percentage within each group
grouped_data <- mutate(grouped_data, percentage = n / sum(n) * 100)

# Ungroup the data
percentage_data <- ungroup(grouped_data)

# Show percentage_data
percentage_data
```

```{r}
# Calculate total count of each country
country_totals <- aggregate(percentage_data$n, by = list(percentage_data$country), FUN = sum)

# Select top 10 countries by total count
top_10_countries <- country_totals[order(country_totals$x, decreasing = TRUE), ]$Group.1[1:10]

# Subset data for top 10 countries only
top_10_data <- subset(percentage_data, country %in% top_10_countries)

# Create pie chart for top 10 countries with improved readability
library(ggplot2)

# Plotting the pie chart
pie_plot <- ggplot(top_10_data, aes(x = "", y = n, fill = type)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar(theta = "y") +
  facet_wrap(~ country, scales = "free_y") +
  geom_text(aes(label = paste0(round(percentage, 2), "%")),
            position = position_stack(vjust = 0.5), color = "white", size = 4, family = "sans") +  # Adjust text size, color, and font family
  theme_void() +
  scale_fill_manual(values = c("#5E81AC", "#E19C24"), labels = c("Movie", "TV Show")) +  # Adjust colors and labels
  theme(legend.position = "bottom", legend.text = element_text(size = 10, family = "sans"), plot.title = element_text(hjust = 0.5, size = 14, family = "sans")) +  # Adjust legend and title text
  labs(fill = "Type", title = "Percentage of Movies vs TV Shows in Top 10 Countries")  # Adjust title

# Show the plot
print(pie_plot)
```

*Use a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.*

@tbl-summarytable shows a summary of the data.

Note the loading of the data providing a **relative** path using the `../../` notation.
(Two dots means a folder up).
You never want to specify an **absolute** path like `C:\ahandel\myproject\results\` because if you share this with someone, it won't work for them since they don't have that path.
You can also use the `here` R package to create paths.
See examples of that below.
**I recommend the `here` package, but I'm showing the other approach here just in case you encounter it.**

```{r}
#| label: tbl-summarytable
#| tbl-cap: "Data summary table."
#| echo: FALSE
resulttable=readRDS("../../results/tables-files/summarytable.rds")
knitr::kable(resulttable)
```

## Basic Statistical Analysis

*To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p\<0.05 means statistical significance" interpretation is not valid.*

The following code below calculates p-values for the coefficients of a multinomial logistic regression model (created in section above on "Statistical Analysis") and prints these values.
The model was fit to predict the rating of Netflix titles based on the country and type (Movie or TV Show).

```{r}

model <- nnet::multinom(rating ~ country + type, data = cleaned_data)

# Summary of the model to get coefficients and standard errors
model_summary <- summary(model)

# Calculate z-values
z_values <- coef(model_summary) / model_summary$standard.errors

# Get p-values from z-values
p_values <- 2 * pnorm(abs(z_values), lower.tail = FALSE)

# View the p-values
print(p_values)
```

Interpretation of the output above:

Each row in your output corresponds to a different rating category's model coefficients for the predictors country and type.

p-values for each coefficient tell you whether the effect of that predictor (e.g., country= France or type= TV Show) on the likelihood of a Netflix title having a particular rating is statistically significant.

Significant p-values (typically \< 0.05) indicate that the corresponding coefficient significantly affects the rating category, adjusting for other factors in the model.

For instance, if the country of Mexico has a p-value less than 0.05 for the rating 'NR', it means that being from Mexico is a significant predictor of a title having an 'NR' rating compared to the baseline rating category, given all other factors constant.

Coefficients with large p-values suggest that those variables do not significantly predict the rating outcome when controlling for other variables.


I want to also get an idea of the distribution of content ratings with Netflix...

```{r}
# Plot for 'rating'
ggplot(data = cleaned_data, aes(x = rating, fill = rating)) +
  geom_bar() +
  labs(title = "Distribution of Netflix Title Ratings", x = "Rating", y = "Count") +
  theme_minimal()

```


@fig-result shows a scatterplot figure produced by one of the R scripts.

```{r}
#| label: fig-result
#| fig-cap: "Height and weight stratified by gender."
#| echo: FALSE
knitr::include_graphics(here("starter-analysis-exercise","results","figures","height-weight-stratified.png"))
```

## Full Analysis

*Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.*

```{r, message=FALSE}
library(tidyr)

# Aggregating data to get count of ratings per country
ratings_by_country <- count(cleaned_data, country, rating)

# Group by country and calculate total
ratings_by_country <- group_by(ratings_by_country, country)
ratings_by_country <- mutate(ratings_by_country, total = sum(n))
ratings_by_country <- ungroup(ratings_by_country)

# Arrange in descending order by total and select top entries
ratings_by_country <- arrange(ratings_by_country, desc(total))
ratings_by_country <- head(ratings_by_country, 100)  # Adjust this to select a number of top entries or a specific threshold

# Spreading data for better visualization handling
ratings_by_country_spread <- spread(ratings_by_country, key = rating, value = n, fill = 0)

# View the aggregated data
head(ratings_by_country_spread)


```


```{r}

# Plotting the distribution of ratings by country
ggplot(ratings_by_country, aes(x = country, y = n, fill = rating)) +
  geom_bar(stat = "identity", position = "fill") +  # 'fill' stacks and normalizes the bar heights to 1
  labs(title = "Distribution of Ratings by Country",
       x = "Country",
       y = "Proportion",
       fill = "Rating") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

```


Example @tbl-resulttable2 shows a summary of a linear model fit.



{{< pagebreak >}}

# Discussion

## Summary and Interpretation

*Summarize what you did, what you found and what it means.*

## Strengths and Limitations

*Discuss what you perceive as strengths and limitations of your analysis.*

## Conclusions

*What are the main take-home messages?*

*Include citations in your Rmd file using bibtex, the list of references will automatically be placed at the end*

This paper [@leek2015] discusses types of analyses.

These papers [@mckay2020; @mckay2020a] are good examples of papers published using a fully reproducible setup similar to the one shown in this template.

Note that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header.
Many more style files for almost any journal [are available](https://www.zotero.org/styles).
You also specify the location of your bibtex reference file in the YAML.
You can call your reference file anything you like, I just used the generic word `references.bib` but giving it a more descriptive name is probably better.

{{< pagebreak >}}

# References
