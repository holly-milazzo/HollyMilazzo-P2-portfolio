---
title: "Manuscript/Report Template for a Data Analysis Project"
subtitle: ""
author: Holly Milazzo
date: today
format:
  html:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../dataanalysis-template-references.bib
csl: ../apa.csl
editor: 
  markdown: 
    wrap: sentence
---

This uses MS Word as output format.
[See here](https://quarto.org/docs/output-formats/ms-word.html) for more information.
You can switch #to other formats, like html or pdf.
See [the Quarto documentation](https://quarto.org/) for other formats.\*/

```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
library(dplyr)
library(ggplot2)
```

# Summary/Abstract

This study explores the hypothesis that the type of content (Movie or TV Show) and the country of origin influence the distribution of age ratings assigned to Netflix titles.
Utilizing a detailed dataset containing information about Netflix titles, we conduct an extensive analysis involving data cleaning, exploratory data analysis, and statistical testing.

{{< pagebreak >}}

## General Background Information

The intent of this analysis is to provide insights into how regional production practices and content types align with age rating distributions, offering valuable information for Netflix's content acquisition and compliance strategies.
This research highlights the importance of understanding content rating trends to better cater to diverse audiences and ensure appropriate content delivery.

## Description of data and data source

Data is on Netflix Movies and TV Shows from Kaggle.com site.
The description says: "The Netflix Titles dataset is a comprehensive compilation of movies and TV shows available on Netflix, covering various aspects such as the title type, director, cast, country of production, release year, rating, duration, genres (listed in), and a brief description. This dataset is instrumental for analyzing trends in Netflix content, understanding genre popularity, and examining the distribution of content across different regions and time periods"

The dataset contains 8,809 observations and the following 12 variables:

-   **show_id:** A unique identifier for each title.

-   **type:** The category of the title, which is either 'Movie' or 'TV Show'

-   **title:** The name of the movie or TV show

-   **director:** The director(s) of the movie or TV show (Contains null values for some entries, especially TV shows where this information might not be applicable)

-   **cast:** The list of main actors/actresses in the title (Some entries might not have this information.)

-   **country:** The country or countries where the movie or TV show was produced.

-   **date_added:** The date the title was added to Netflix.

-   **release_year:** The year the movie or TV show was originally released.

-   **rating:** The age rating of the title.

-   **duration:** The duration of the title, in minutes for movies and seasons for TV shows

-   **listed_in:** The genres the title falls under.

-   **description:** A brief summary of the title.

## Questions/Hypotheses to be addressed

*State the research questions you plan to answer with this analysis.*

"How do the type of content (Movie or TV Show) and the country of origin affect the distribution of age ratings on Netflix titles?"

This question focuses on understanding the relationship between content type, country of origin, and age ratings, which can provide valuable insights into regional production practices and content rating trends on Netflix

To cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the #bibtex file specified in the YAML header above (here `dataanalysis_template_references.bib`) and have the right bibtex key.
#Then you can include like this:

Examples of reproducible research projects can for instance be found in [@mckay2020; @mckay2020a]

{{< pagebreak >}}

# Methods

*Describe your methods. That should describe the data, the cleaning processes, and the analysis approaches. You might want to provide a shorter description here and all the details in the supplement.*

I will be using EDA initially and from there branching out into some hypothesis testing using Multinomial Logistic Regression to see if there is any association between country, content type, and rating.

## Data Acquisition

I imported the data for Netflix Movies and TV Shows which was available on Kaggle.com site.
My raw data file is available through file path folders: starter-analysis-exercise \> data \> raw-data \> netflix_titles.xlsx

## Data Import and Cleaning

The file path to my code file for cleaning my dataset is: starter-analysis-exercise \> code \> processing-code \> processingfile

First I imported the data...

```{r}
data_location <- here::here("starter-analysis-exercise","data","raw-data","exampledata.xlsx")
rawdata <- readxl::read_excel(data_location)
```

here are some of the initial cleaning techniques and a few reasons why I chose to do them:

-   For the country column, I filled missing values with the mode (most frequently occurring country).

-   Converted the date_added to a Date format as a crucial step for any potential time series or date-related analysis.

-   Converted type to a factor since I am planning on performing statistical tests and/or modeling that may need categorical input features.

```{r}
# Handling missing values

rawdata$director[is.na(rawdata$director)] <- "Unknown"

# Fill missing 'country' values with the mode (most frequent value)
mode_country <- names(sort(table(rawdata$country), decreasing = TRUE))[1]
rawdata$country[is.na(rawdata$country)] <- mode_country

# Safe conversion of date formats with error handling
rawdata$date_added <- as.Date(rawdata$date_added, format = "%m/%d/%Y")
if(any(is.na(rawdata$date_added))) {
  warning("There were errors in date conversion. Check date formats.")
}

# Standardizing categorical variables

rawdata$type <- as.factor(rawdata$type)

# Display the cleaned data
head(rawdata)
```

I also needed to do some clean up when it came to content 'type' as it included unwanted values...

```{r}
# Remove rows where 'type' is "William Wyler" or NA
cleaned_data <- rawdata[rawdata$type != "William Wyler" & rawdata$type != "Unknown" & !is.na(rawdata$type), ]


```

```{r}
summary(cleaned_data)
```



## Statistical Analysis

*Explain anything related to your statistical analyses.*

The relevant variables I'll be using during my statistical analysis to determine how regional production practices and content types align with age rating distributions will be: Country, Type, and Rating.

Let's double check if there is any other missing data in my cleaned_data before I perform my analysis... nothing significant in 3 variables I'll be using.

```{r}
# Calculate the number of missing values for each column in cleaned_data
missing_data_summary <- sapply(cleaned_data, function(x) sum(is.na(x)))

# Print the summary of missing data
print(missing_data_summary)

```

I also want to check for any outliers as well...

```{r, message=FALSE}
# Create a boxplot for each numeric variable in the dataframe
numeric_vars <- sapply(cleaned_data, is.numeric)
if(any(numeric_vars)) {
  # Filter only numeric columns
  numeric_data <- cleaned_data[, numeric_vars]

  # Melt the data for easy plotting with ggplot2
  library(reshape2)
  long_data <- melt(numeric_data)

  # Plot
  ggplot(long_data, aes(x = variable, y = value)) +
    geom_boxplot(outlier.colour = "red", outlier.shape = 1) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Boxplot for Each Numeric Variable", x = "Variables", y = "Values")
} else {
  print("No numeric variables found for plotting.")
}
```

Given my hypothesis, which aims to explore how the type of content (Movie or TV Show) and the country of origin influence the distribution of age ratings on Netflix titles, regression testing does not seem like the best testing method because I using 2 categorical variables (Type and Rating) as target variables.My 'rating' variable is not ordinal either which means we'd also leave out performing logistic regression.

I believe the best testing methods in this case are either Chi-square (to test independence) or Multinomial Logistic Regression.
MLR would be useful since the 'Rating' has multiple categories without order and would allow me to model the probability of each rating category as a function of 'Type' and 'Country'.

I will need install the following packages for the next part of my analysis

```{r}
library(nnet)
library(forcats)
```

Initially, when I ran the model it gave an error due to the complexity in the number of parameters it created based on the variations of categories I have in my variables.

ChatGPT recommended I use the code below to create a decay term for regularization, which helps to manage the complexity of the model by shrinking the regression coefficients.

With the convergence of my multinomial logistic regression as indicated by "converged" in the output below, the next steps involve interpreting the model's results and using them to validate my hypothesis or make further decisions.

```{r}
# Assuming 'Country' has many categories, we reduce them
cleaned_data$country <- fct_lump_n(cleaned_data$country, n = 10)  # Keeps the top 10 countries, others lumped into "Other"
cleaned_data$country <- factor(cleaned_data$country)

# Fit the model with increased decay for regularization

fit <- multinom(type ~ country + rating, data = cleaned_data, MaxNWts = 10000, decay = 0.1)

```

Now to run my multinomial model....

```{r}
cleaned_data$country <- as.factor(cleaned_data$country)
cleaned_data$type <- as.factor(cleaned_data$type)
cleaned_data$rating <- as.factor(cleaned_data$rating)


multinom_model <- multinom(rating ~ country + type, data = cleaned_data)

# Summary of the model
head(multinom_model)

```


```{r}

probabilities <- predict(multinom_model, type = "probs")

head(probabilities)
```



{{< pagebreak >}}

# Results

Interpretation of Multinomial Logistic Regression model results

The results from the MLR provided a complex but informative view into how different countries and types of content (e.g., Movies vs. TV Shows) relate to the ratings of Netflix titles.
Here's a breakdown and interpretation of the results:

The model successfully converged after 100 iterations, indicating that the algorithm was able to find a stable solution.
The final value (14611.228013) of the deviance indicates the fit of the model to my data.

The coefficients for each level of the factors (Country, Type) show how each category relates to the probability of the content having a specific rating compared to the baseline category, however, without knowing the standard errors or p-values it's challenging to discuss the statistical significance of each coefficient - only the magnitude and direction (positive or negative) of the coefficients can provide insights at this point.

## Exploratory/Descriptive Analysis

Distribution between Movies and TV Shows:

```{r}
# Perform the group_by and summarise operations
type_distribution <- aggregate(. ~ type, data = cleaned_data, FUN = length)
names(type_distribution)[2] <- "count"

# Plot the distribution of content types
barplot(height = type_distribution$count,
        names.arg = type_distribution$type,
        col = c("purple", "orange"),
        main = "Distribution of Content Types - Movies v TV Shows",
        xlab = "Type",
        ylab = "Count",
        las = 1) # las = 1 makes axis labels horizontal
```

We see from the distribution that it appears movies are being streamed substantially more than TV shows, but to get a better sense of this let's represent it as a percentage instead

```{r}
type_distribution <- aggregate(. ~ type, data = cleaned_data, FUN = length)
names(type_distribution)[2] <- "count"

type_distribution$percentage <- round((type_distribution$count / sum(type_distribution$count)) * 100, 1)

labels <- paste(type_distribution$type, type_distribution$percentage, "%")

pie(type_distribution$count,
    labels = labels,
    col = c("purple", "orange"),
    main = "Percentage of Movies vs TV Shows")
```

Now I'd like to see which countries the Movie/TV show content originate from

```{r}
library(ggplot2)

country_counts <- head(sort(table(cleaned_data$country), decreasing = TRUE), 10)

# Convert to data frame for ggplot
country_df <- data.frame(
  country = names(country_counts),
  count = as.numeric(country_counts)
)

# Create the bar chart
p <- ggplot(country_df, aes(x = reorder(country, -count), y = count)) +
  geom_bar(stat = "identity", fill = "purple") +
  geom_text(aes(label = count), vjust = -0.3) +
  labs(x = "Country", y = "Count", title = "Top 10 Countries (Top 3 Highlighted)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_bar(data = country_df[1:3, ], aes(x = country, y = count), stat = "identity", fill = "orange")

print(p)
```


Let's also explore what the content consumption is like between countries...

```{r}
# Count occurrences of each country and type
count_data <- count(cleaned_data, country, type)

# Group by country
grouped_data <- group_by(count_data, country)

# Calculate percentage within each group
grouped_data <- mutate(grouped_data, percentage = n / sum(n) * 100)

# Ungroup the data
percentage_data <- ungroup(grouped_data)

# Show percentage_data
percentage_data
```

```{r}
# Calculate total count of each country
country_totals <- aggregate(percentage_data$n, by = list(percentage_data$country), FUN = sum)

# Select top 10 countries by total count
top_10_countries <- country_totals[order(country_totals$x, decreasing = TRUE), ]$Group.1[1:10]

# Subset data for top 10 countries only
top_10_data <- subset(percentage_data, country %in% top_10_countries)

# Create pie chart for top 10 countries with improved readability
library(ggplot2)

# Plotting the pie chart
pie_plot <- ggplot(top_10_data, aes(x = "", y = n, fill = type)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar(theta = "y") +
  facet_wrap(~ country, scales = "free_y") +
  geom_text(aes(label = paste0(round(percentage, 2), "%")),
            position = position_stack(vjust = 0.5), color = "white", size = 4, family = "sans") +  # Adjust text size, color, and font family
  theme_void() +
  scale_fill_manual(values = c("purple", "orange"), labels = c("Movie", "TV Show")) +  # Adjust colors and labels
  theme(legend.position = "bottom", legend.text = element_text(size = 10, family = "sans"), plot.title = element_text(hjust = 0.5, size = 14, family = "sans")) +  # Adjust legend and title text
  labs(fill = "Type", title = "Percentage of Movies vs TV Shows in Top 10 Countries")  # Adjust title

# Show the plot
print(pie_plot)
```



Note the loading of the data providing a **relative** path using the `../../` notation.
(Two dots means a folder up).
You never want to specify an **absolute** path like `C:\ahandel\myproject\results\` because if you share this with someone, it won't work for them since they don't have that path.
You can also use the `here` R package to create paths.
See examples of that below.
**I recommend the `here` package, but I'm showing the other approach here just in case you encounter it.**

## Basic Statistical Analysis

*To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p\<0.05 means statistical significance" interpretation is not valid.*

Given my hypothesis...

My predictor Variables (Independent Variables):

- type (Movie or TV Show)
- country (Country of origin)

and my response Variable (Dependent Variable):

- rating (Age rating assigned to Netflix titles)

Let's perform some basic statistics to examine the associations between the outcome variable (rating) and each individual predictor variable (type and country).

```{r}
# Cross-tabulation of type and rating
type_rating_table <- table(rawdata$type, rawdata$rating)
print(type_rating_table)
```

```{r}
# Chi-square test of independence
type_rating_chi2 <- chisq.test(type_rating_table)
print(type_rating_chi2)
```
Interpretation of results:

The chi-square test statistic is very large (9853.7), and the p-value is extremely small (less than 2.2e-16). This indicates that there is a significant association between type and rating. In other words, the type of content (Movie or TV Show) and the rating are not independent; they are related

what about the association between country and rating though...

```{r}
# Frequency distribution of rating by country
country_rating_table <- table(rawdata$country, rawdata$rating)

```

```{r}

country_rating_chi2 <- chisq.test(country_rating_table)
print(country_rating_chi2)

```
Interpretation of results:

It appears, again, that the chi-square test statistic is very large (26495), and the p-value is extremely small (less than 2.2e-16). Which indicates that there is a significant association between country and rating. In other words, the country of origin and the rating are not independent; they are related.

Given the high association between all my variables (type, country, and rating), I will do some a bit more exploring. 

First, I could visually explore the association between my categorical variables using a stacked bar chart, and then run a random forest model to understand the importance of using different predictors and their relationships


```{r}

rawdata$country <- sapply(strsplit(rawdata$country, ", "), `[`, 1)


unique(rawdata$country)
```


```{r}
filtered_data <- rawdata %>%
  filter(!is.na(type))

# Optionally, filter the data to include only a subset of countries
# For example, top 10 countries by count of titles
top_countries <- filtered_data %>%
  count(country, sort = TRUE) %>%
  top_n(10, n) %>%
  pull(country)

filtered_data <- filtered_data %>%
  filter(country %in% top_countries)

# Create the bar chart
ggplot(filtered_data, aes(x = country, fill = rating)) +
  geom_bar(position = "fill") +
  facet_wrap(~ type, scales = "free_y") +
  labs(title = "Proportion of Ratings by Type and Country", x = "Country", y = "Proportion") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom")
```

Before getting started with our random forest we'll need to install some necessary packages

```{r}
library(caret)
library(randomForest)
library(mice)
```

In this step we convert our categorical variables into factors:

```{r}
filtered_data$type <- as.factor(filtered_data$type)
filtered_data$country <- as.factor(filtered_data$country)
filtered_data$rating <- as.factor(filtered_data$rating)
```


In this step we somewhat use imputation (replace 'na' in our data with mode):

```{r}
calculate_mode <- function(x) {
  uniq_x <- unique(x)
  uniq_x[which.max(tabulate(match(x, uniq_x)))]
}

# Function to impute missing values
impute_missing <- function(df) {
  df[] <- lapply(df, function(col) {
    if (is.numeric(col)) {
      # Impute numeric columns with median
      col[is.na(col)] <- median(col, na.rm = TRUE)
    } else {
      # Impute categorical columns with mode
      col[is.na(col)] <- calculate_mode(col)
    }
    return(col)
  })
  return(df)
}
```


Now to split the data into training and test sets...

```{r}
imputed_data <- impute_missing(filtered_data)


set.seed(123)
train_index <- createDataPartition(imputed_data$rating, p = 0.8, list = FALSE)
train_data <- imputed_data[train_index, ]
test_data <- imputed_data[-train_index, ]
```

Now to train the random forest model...

```{r}
set.seed(321) 
rf_model <- randomForest(rating ~ type + country, data = train_data, ntree = 500, mtry = 2, importance = TRUE)


print(rf_model)
```

And lastly, let's evaluate the performance of our random forest:

```{r}
predictions <- predict(rf_model, test_data)
confusion_matrix <- confusionMatrix(predictions, test_data$rating)

head(confusion_matrix)
```


```{r}
varImpPlot(rf_model)
```


## Interpretation


The results from the random forest model's performance are summarized in the confusion matrix and accompanying statistics. The overall accuracy of the model is 37.62%, indicating that it correctly classified approximately 38% of the instances. This accuracy is slightly better than the No Information Rate (NIR) of 34.21%, which represents the accuracy we would get by always predicting the most frequent class. The confidence interval for the model's accuracy ranges from 35.08% to 40.22%, suggesting the true accuracy lies within this interval. The p-value (0.003985) indicates that the model’s accuracy is significantly better than random guessing.

However, the Kappa value of 0.0843 reveals poor agreement between the predicted and actual classifications when accounting for chance. The statistics by class show varying performance across different rating categories. For instance, the sensitivity for "TV-14" is 42.55%, meaning the model correctly identified about 43% of "TV-14" ratings. The specificity for "TV-14" is higher at 88.84%, indicating that the model correctly identified about 89% of non-"TV-14" ratings.

The precision for "TV-14" is 53.10%, meaning that just over half of the predicted "TV-14" ratings were correct. In contrast, the model struggles with classes that have low prevalence in the dataset, resulting in low sensitivity and precision for those classes.

Overall, the model performs moderately well, particularly for certain classes like "TV-MA" which have higher sensitivity and balanced accuracy. However, the model's performance could be improved by addressing class imbalance, adding more features, tuning hyperparameters, and potentially using more complex ensemble methods. These steps could help achieve better classification accuracy and agreement between predicted and actual ratings.

## Conclusion

The results indicate that the country of origin significantly influences the distribution of age ratings assigned to Netflix titles, as shown by the high importance of the country variable in the random forest model. The substantial decrease in model accuracy and increase in node impurity when the country variable is excluded further supports this finding. While the type of content (Movie or TV Show) also affects the distribution of age ratings, its impact is less pronounced compared to the country of origin. Excluding the type variable results in a smaller decrease in model performance. Overall, both predictor variables—type and country—contribute to the prediction of age ratings, but the country of origin has a more dominant influence, highlighting that while both factors are important, the country's impact is stronger.


{{< pagebreak >}}




{{< pagebreak >}}

## References

I did get some of my EDA inspiration from : [Link](https://www.kaggle.com/code/lp2595/netflix-movies-and-tv-shows-eda#WOW!-Mostly,-Contents-from-Japan-and-South-Korea-are-TV-Shows)

Here's a video tutorial on how to say "Netflix and Chill" in 26 different languages:[Link](https://www.youtube.com/watch?app=desktop&v=btKF84-y8os)
